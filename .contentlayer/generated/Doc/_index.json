[
  {
    "title": "Prometheus and Grafana: The Metric Monitoring Titans",
    "body": {
      "raw": "Your cloud native empire will never have looked so beautiful...\n<!--more-->\n\nIn my last article, I mentioned an open-source platform called Prometheus. Now if you are in any way involved with the cloud native ecosystem, you will probably have come across it. After all, it shares its name with a Greek Titan that starred in one of the world famous 'Alien' movies 👽. But then I tell you that it is a monitoring and alerting toolkit that includes data scraping and storing, it's own querying language called 'PromQL' and a built in alert manager. Yes, that sounds great... but... what does that mean? Well here we go again!\n\n![Prometheus Gif](/img/04-Prometheus/prometheusmovie.gif \"That look the sysadmin makes when he first sees a graph of his cluster metrics on Prometheus\")\n\n## Prometheus... 🤷‍♂️\nNow let's build ourselves a scenario. You're like me, and you've just set up your first all singing, all dancing kubernetes cluster on GKE 🎵. Whether you know it or not (I definitely didn't to begin with), this is a very simple, turnkey experience. What I mean by this is that from go, a lot of the clusters components are setup for you, and their presence just fades into the background (within the darkest depths of the Google Cloud Platform 👻).\n\nYou think to yourself, \"I wonder how my cluster is performing... What pods are using up the most memory, how much traffic am I getting through my contour ingress controller?\". Well.. that certainly is an interesting question. You have a scroll through the GCP web UI and the built in functions just throw it into your lap and you don't need to spare a second thought. But... where are those metrics really coming from? and if you hadn't asked yourself this question... and then spun up something more vanilla afterwards, like Kubeadm; why aren't these same capabilities just given to to me in the same way? Now we're talking 🕵🏻‍♂️.\n\n![Prometheus Gif](/img/04-Prometheus/GKEmonitoring.png \"How the GKE Web UI Looks\")\n\n[Prometheus](https://github.com/prometheus/prometheus) is a set of tools that you'll want to get for a thorough logging and monitoring experience on many container orchestrators. And what makes it so widely acclaimed? Well, a couple of things. First of all it has a powerfully simple querying language, so it's users can analyse their Kubernetes, Docker Swarm, Apache Mesos, Cloud Foundry... or just Kubernetes 🙃 clusters down to the minute details with ease.\n\nWhats more? Prometheus was the second project to be officially supported by the Cloud Native Computing Foundation, along with Kubernetes and Envoy (mentioned in the first article for this [blog](https://blog.chaosinthe.dev/posts/first-posts/), take a look). This support gives a company that plans to integrate its applications with Prometheus tooling, the assurance that it will be an industry standard going into the future.  For this reason, this makes it a perfect candidate for a metrics provider, and it has seen wide spread adoption; with people speculating that the number of organisations using it could be in the tens of thousands.\n\n## So how is all of this possible?\n\nSo as I said in the previous section, Prometheus is far more than a Kubernetes concept. It doesn't stipulate on the application running, and it has the capability of using metrics on almost any application provided it is configured correctly. In general, it requires that the workload provides the metrics for it using two components:\n\n- Prometheus Exporter: These are libraries and servers that do the job of exporting the metrics generated by applications/services in your environment as Prometheus friendly metrics 😊\n- Prometheus HTTP Endpoint: The exporter then sends these metrics to a HTTP endpoint, which is a port on the applications http address that sits open, providing the metrics that Prometheus requires for the amazing stuff it'll do later on.\n\nOk, so how does Prometheus get hold of these metrics that are now spilling out of the configured port? Well, Prometheus has a server application conveniently named 'Prometheus Server', that 'scrapes' up the metrics sitting on the aforementioned ports, organises them into a time series database (TSDB), and throws it into a storage volume somewhere, amazing \n\n\n![Prometheus Gif](/img/04-Prometheus/PromArch.png \"How it all looks under the hood\")\n\n### But I thought you said there was an alert manager?\nOh yes, you're right there. Prometheus does indeed have its own dedicated alert manager. Embedded within the Prometheus server are capabilities that allow the user to define alerting rules based on the metrics provide by the cluster. For instance, want to know when there is high request latency for a web page on your server? No problem. This can be done easily if you give the server a correctly configured alert rules yaml. For example:\n\n```yaml\ngroups:\n- name: example\n  rules:\n  - alert: HighRequestLatency\n    expr: job:request_latency_seconds:mean5m{job=\"myjob\"} > 0.5\n    for: 10m\n    labels:\n      severity: page\n    annotations:\n      summary: High request latency\n```\nWow, markdown makes putting yaml in a web article super easy 🆒. Anyway, where was I... ah yes.\n\nOnce this has been deployed to the prometheus server, any metrics that meet these alert conditions will send the relevant alert to the manager. The alert manager can be reached easily through a web ui, where you can view all the alerts sent from the server, or there is something jazzy called the Alertmanager webhook receiver 😲. What does this mean? well it means you can have your alerts delivered to a service of your choice. such as? well, you name it; they do it. SMS, Email, Telegram, Slack, Microsoft Teams, ServiceNow, Zoom, Alibaba Dingtalk, Rocket Chat (looks so awesome). The list goes on. Now you truly can make yourself feel like you have your own starship enterprise.\n\n{{< figure src=\"/img/04-Prometheus/homerdoomed.gif\">}}\n\n## PromQL... Where the real fun begins 🕺\n\nAs I mentioned, the Alertmanager does have it's own dedicated web-ui, and so does the Prometheus server. When you access the Prometheus web-ui (through a default port of 9090), you're faced with a pretty simple, yet bland looking interface. It has a simple text input box labelled 'Expression', with a button below it that says 'Execute'. Very exciting, let's start playing.\n\n{{< figure src=\"/img/04-Prometheus/PromGUI.png\">}}\n\nSo by 'Expression', Prometheus means that it intends for the user to input syntax that 'queries' for some metrics sitting on the Prometheus Database (TSDB). This will be your way of telling prometheus, \"hey, fetch me the CPU utilisation data of all the containers running on my kubernetes cluster, and return it organised in a certain way. Then finally if all goes well, it'll plot that data in the graph box sat below in the GUI. But just like a any extraterrestrial being, you must ask yourself 'what language does it speak?'. Well thankfully, it isn't Clingon. In fact, its querying language, PromSQL, is one of the reasons why this tool has found such popularity. As you can see below, the syntax is actually very simple to understand.. a.k.a it's pretty much in plain english, hoorah! If you haven't deduced already, this example fetches the amount of http GET requests taking place in the staging, testing and development environments... easy 😂.\n\n``` PromSQL\nhttp_requests_total{environment=~\"staging|testing|development\",method!=\"GET\"}\n```\n\n## But I was hoping for something prettier 💋\n\nWell to be honest... so was I. But don't worry, I have good news!\n\nIt's time for another mystical platform name into the mix... it's slick, it's shiny, it's...\n\n{{< figure src=\"/img/04-Prometheus/Grafana.png\" >}}\n\n\n<figure>\n<img src=\"/img/04-Prometheus/Grafana.gif\" />\n<figcaption>\n<h4>I know right?</h4>\n</figcaption>\n</figure>\n\n![](/img/04-prometheus/Grafana.png \"I know right?\")\n\nSo welcome to the magical land of [Grafana](https://github.com/grafana/grafana). Where you can make use of PromSQL and the prometheus server APIs to visualise your generated metrics on highly configurable dashboards. That's right, we've just taken your Starship Enterprise to the next level 🛰. Each dashboard consists of one or more panels that can be arranged into rows. Of course usually each panel on the dashboard is related to each other. So you would have for instance a dashboard of panels for information regarding your kubernetes clusters CPU/Mem/Disk utilisation, and another dashboard that displays the ingresses of your applications sitting within the cluster. Then you could even have another dashboard that showed the geographical location of each request to your site in real time... yes I absolutely need to look into doing it for this site 🙌. The sky really is the limit... if it's data that can be hoovered up by prometheus into the database, it can be visualised on Grafana with some configuration. And what's even cooler? You can make specific dashboards public so that you can show them to friends... or uh... colleagues easily. Don't worry though, you will still have full access to your precious infrastructure under lock and key.\n\nI hear you, I hear you, you want to see what this interface looks like in real life. Well good news! Thanks to the open-source attitude some organisations take towards these platforms, certain dashboards are available for anyone to look at. For instance, [CERN](https://monit-grafana-open.cern.ch/d/000000523/home?orgId=16), [CNCF](https://devstats.cncf.io/), the [Beehive Project](https://weather.hiveeyes.org/grafana/d/start/welcome?kiosk&orgId=1&refresh=15m) and many more make some of their dashboards fully accessible for the world to see. I've just wasted the last 30 minutes looking around them and they're amazing, so feel free to give them a look if you have any more free time.\n\n\n## I'm sold, i'm sold! How do I get it on my Kubernetes cluster?\n\nHow do you get it? Well that's maybe even better than the joys of the previous section. [This](https://github.com/prometheus/prometheus) github repository named kube-prometheus is all you need to get yourself started with your very own Prometheus server, web UI, AlertManager, and even Grafana, to start viewing your empire like a king on day 0. I used it on GKE, and it was super easy to get going. In fact I feel this task was when things started to click in my head about kubernetes as a platform, which was very rewarding.\n\n## 'Scraping' up the last bits and pieces\n\nSo that's it. We've gained some clarity on yet another cloud native tool, and taken a shallow dive into what is possible when Kubernetes teams up with Kubernetes and Grafana to give nerds like myself a full view of their estate; but also a window view for anyone else interested. For any organisation running Kubernetes or a cloud-native platform like it, these tools really are a no brainer... they are the industry standard... and well... why wouldn't you want to have what I just showed you? It's so awesome!\n\nI'll leave you with another Youtube video, as this tends to be the standard way to finish these articles. Tom Wilkie, one of the Prometheus Developers, gave a great talk back in 2018, which gives a more thorough and detailed tour of the Prometheus world, and how that can be linked up with Grafana. So I hope you enjoyed this weeks instalment, and as always any feedback at all is more than welcome.\n\n{{< youtube kG9p417sC3I >}}\n",
      "html": "<p>Your cloud native empire will never have looked so beautiful...</p>\n<p>In my last article, I mentioned an open-source platform called Prometheus. Now if you are in any way involved with the cloud native ecosystem, you will probably have come across it. After all, it shares its name with a Greek Titan that starred in one of the world famous 'Alien' movies 👽. But then I tell you that it is a monitoring and alerting toolkit that includes data scraping and storing, it's own querying language called 'PromQL' and a built in alert manager. Yes, that sounds great... but... what does that mean? Well here we go again!</p>\n<p><img src=\"/img/04-Prometheus/prometheusmovie.gif\" alt=\"Prometheus Gif\" title=\"That look the sysadmin makes when he first sees a graph of his cluster metrics on Prometheus\"></p>\n<h2>Prometheus... 🤷‍♂️</h2>\n<p>Now let's build ourselves a scenario. You're like me, and you've just set up your first all singing, all dancing kubernetes cluster on GKE 🎵. Whether you know it or not (I definitely didn't to begin with), this is a very simple, turnkey experience. What I mean by this is that from go, a lot of the clusters components are setup for you, and their presence just fades into the background (within the darkest depths of the Google Cloud Platform 👻).</p>\n<p>You think to yourself, \"I wonder how my cluster is performing... What pods are using up the most memory, how much traffic am I getting through my contour ingress controller?\". Well.. that certainly is an interesting question. You have a scroll through the GCP web UI and the built in functions just throw it into your lap and you don't need to spare a second thought. But... where are those metrics really coming from? and if you hadn't asked yourself this question... and then spun up something more vanilla afterwards, like Kubeadm; why aren't these same capabilities just given to to me in the same way? Now we're talking 🕵🏻‍♂️.</p>\n<p><img src=\"/img/04-Prometheus/GKEmonitoring.png\" alt=\"Prometheus Gif\" title=\"How the GKE Web UI Looks\"></p>\n<p><a href=\"https://github.com/prometheus/prometheus\">Prometheus</a> is a set of tools that you'll want to get for a thorough logging and monitoring experience on many container orchestrators. And what makes it so widely acclaimed? Well, a couple of things. First of all it has a powerfully simple querying language, so it's users can analyse their Kubernetes, Docker Swarm, Apache Mesos, Cloud Foundry... or just Kubernetes 🙃 clusters down to the minute details with ease.</p>\n<p>Whats more? Prometheus was the second project to be officially supported by the Cloud Native Computing Foundation, along with Kubernetes and Envoy (mentioned in the first article for this <a href=\"https://blog.chaosinthe.dev/posts/first-posts/\">blog</a>, take a look). This support gives a company that plans to integrate its applications with Prometheus tooling, the assurance that it will be an industry standard going into the future.  For this reason, this makes it a perfect candidate for a metrics provider, and it has seen wide spread adoption; with people speculating that the number of organisations using it could be in the tens of thousands.</p>\n<h2>So how is all of this possible?</h2>\n<p>So as I said in the previous section, Prometheus is far more than a Kubernetes concept. It doesn't stipulate on the application running, and it has the capability of using metrics on almost any application provided it is configured correctly. In general, it requires that the workload provides the metrics for it using two components:</p>\n<ul>\n<li>Prometheus Exporter: These are libraries and servers that do the job of exporting the metrics generated by applications/services in your environment as Prometheus friendly metrics 😊</li>\n<li>Prometheus HTTP Endpoint: The exporter then sends these metrics to a HTTP endpoint, which is a port on the applications http address that sits open, providing the metrics that Prometheus requires for the amazing stuff it'll do later on.</li>\n</ul>\n<p>Ok, so how does Prometheus get hold of these metrics that are now spilling out of the configured port? Well, Prometheus has a server application conveniently named 'Prometheus Server', that 'scrapes' up the metrics sitting on the aforementioned ports, organises them into a time series database (TSDB), and throws it into a storage volume somewhere, amazing</p>\n<p><img src=\"/img/04-Prometheus/PromArch.png\" alt=\"Prometheus Gif\" title=\"How it all looks under the hood\"></p>\n<h3>But I thought you said there was an alert manager?</h3>\n<p>Oh yes, you're right there. Prometheus does indeed have its own dedicated alert manager. Embedded within the Prometheus server are capabilities that allow the user to define alerting rules based on the metrics provide by the cluster. For instance, want to know when there is high request latency for a web page on your server? No problem. This can be done easily if you give the server a correctly configured alert rules yaml. For example:</p>\n<pre><code class=\"language-yaml\">groups:\n- name: example\n  rules:\n  - alert: HighRequestLatency\n    expr: job:request_latency_seconds:mean5m{job=\"myjob\"} > 0.5\n    for: 10m\n    labels:\n      severity: page\n    annotations:\n      summary: High request latency\n</code></pre>\n<p>Wow, markdown makes putting yaml in a web article super easy 🆒. Anyway, where was I... ah yes.</p>\n<p>Once this has been deployed to the prometheus server, any metrics that meet these alert conditions will send the relevant alert to the manager. The alert manager can be reached easily through a web ui, where you can view all the alerts sent from the server, or there is something jazzy called the Alertmanager webhook receiver 😲. What does this mean? well it means you can have your alerts delivered to a service of your choice. such as? well, you name it; they do it. SMS, Email, Telegram, Slack, Microsoft Teams, ServiceNow, Zoom, Alibaba Dingtalk, Rocket Chat (looks so awesome). The list goes on. Now you truly can make yourself feel like you have your own starship enterprise.</p>\n<p>{{&#x3C; figure src=\"/img/04-Prometheus/homerdoomed.gif\">}}</p>\n<h2>PromQL... Where the real fun begins 🕺</h2>\n<p>As I mentioned, the Alertmanager does have it's own dedicated web-ui, and so does the Prometheus server. When you access the Prometheus web-ui (through a default port of 9090), you're faced with a pretty simple, yet bland looking interface. It has a simple text input box labelled 'Expression', with a button below it that says 'Execute'. Very exciting, let's start playing.</p>\n<p>{{&#x3C; figure src=\"/img/04-Prometheus/PromGUI.png\">}}</p>\n<p>So by 'Expression', Prometheus means that it intends for the user to input syntax that 'queries' for some metrics sitting on the Prometheus Database (TSDB). This will be your way of telling prometheus, \"hey, fetch me the CPU utilisation data of all the containers running on my kubernetes cluster, and return it organised in a certain way. Then finally if all goes well, it'll plot that data in the graph box sat below in the GUI. But just like a any extraterrestrial being, you must ask yourself 'what language does it speak?'. Well thankfully, it isn't Clingon. In fact, its querying language, PromSQL, is one of the reasons why this tool has found such popularity. As you can see below, the syntax is actually very simple to understand.. a.k.a it's pretty much in plain english, hoorah! If you haven't deduced already, this example fetches the amount of http GET requests taking place in the staging, testing and development environments... easy 😂.</p>\n<pre><code class=\"language-PromSQL\">http_requests_total{environment=~\"staging|testing|development\",method!=\"GET\"}\n</code></pre>\n<h2>But I was hoping for something prettier 💋</h2>\n<p>Well to be honest... so was I. But don't worry, I have good news!</p>\n<p>It's time for another mystical platform name into the mix... it's slick, it's shiny, it's...</p>\n<p>{{&#x3C; figure src=\"/img/04-Prometheus/Grafana.png\" >}}</p>\n<p><img src=\"/img/04-prometheus/Grafana.png\" alt=\"\" title=\"I know right?\"></p>\n<p>So welcome to the magical land of <a href=\"https://github.com/grafana/grafana\">Grafana</a>. Where you can make use of PromSQL and the prometheus server APIs to visualise your generated metrics on highly configurable dashboards. That's right, we've just taken your Starship Enterprise to the next level 🛰. Each dashboard consists of one or more panels that can be arranged into rows. Of course usually each panel on the dashboard is related to each other. So you would have for instance a dashboard of panels for information regarding your kubernetes clusters CPU/Mem/Disk utilisation, and another dashboard that displays the ingresses of your applications sitting within the cluster. Then you could even have another dashboard that showed the geographical location of each request to your site in real time... yes I absolutely need to look into doing it for this site 🙌. The sky really is the limit... if it's data that can be hoovered up by prometheus into the database, it can be visualised on Grafana with some configuration. And what's even cooler? You can make specific dashboards public so that you can show them to friends... or uh... colleagues easily. Don't worry though, you will still have full access to your precious infrastructure under lock and key.</p>\n<p>I hear you, I hear you, you want to see what this interface looks like in real life. Well good news! Thanks to the open-source attitude some organisations take towards these platforms, certain dashboards are available for anyone to look at. For instance, <a href=\"https://monit-grafana-open.cern.ch/d/000000523/home?orgId=16\">CERN</a>, <a href=\"https://devstats.cncf.io/\">CNCF</a>, the <a href=\"https://weather.hiveeyes.org/grafana/d/start/welcome?kiosk&#x26;orgId=1&#x26;refresh=15m\">Beehive Project</a> and many more make some of their dashboards fully accessible for the world to see. I've just wasted the last 30 minutes looking around them and they're amazing, so feel free to give them a look if you have any more free time.</p>\n<h2>I'm sold, i'm sold! How do I get it on my Kubernetes cluster?</h2>\n<p>How do you get it? Well that's maybe even better than the joys of the previous section. <a href=\"https://github.com/prometheus/prometheus\">This</a> github repository named kube-prometheus is all you need to get yourself started with your very own Prometheus server, web UI, AlertManager, and even Grafana, to start viewing your empire like a king on day 0. I used it on GKE, and it was super easy to get going. In fact I feel this task was when things started to click in my head about kubernetes as a platform, which was very rewarding.</p>\n<h2>'Scraping' up the last bits and pieces</h2>\n<p>So that's it. We've gained some clarity on yet another cloud native tool, and taken a shallow dive into what is possible when Kubernetes teams up with Kubernetes and Grafana to give nerds like myself a full view of their estate; but also a window view for anyone else interested. For any organisation running Kubernetes or a cloud-native platform like it, these tools really are a no brainer... they are the industry standard... and well... why wouldn't you want to have what I just showed you? It's so awesome!</p>\n<p>I'll leave you with another Youtube video, as this tends to be the standard way to finish these articles. Tom Wilkie, one of the Prometheus Developers, gave a great talk back in 2018, which gives a more thorough and detailed tour of the Prometheus world, and how that can be linked up with Grafana. So I hope you enjoyed this weeks instalment, and as always any feedback at all is more than welcome.</p>\n<p>{{&#x3C; youtube kG9p417sC3I >}}</p>"
    },
    "_id": "blog/04-Prometheus.md",
    "_raw": {
      "sourceFilePath": "blog/04-Prometheus.md",
      "sourceFileName": "04-Prometheus.md",
      "sourceFileDir": "blog",
      "contentType": "markdown",
      "flattenedPath": "blog/04-Prometheus"
    },
    "type": "Doc"
  },
  {
    "title": "When disaster strikes, count on... Velero?",
    "body": {
      "raw": "\n\nThe open source tool that makes backing up your Kubernetes Cluster plain sailing!\n<!--more-->\n\nWell surprise surprise, it looks like I'm back! Not at all the length of time that I was planning to be away for, but certain events (that I'm sure you will not want to spend another minute hearing about) led me to put our curious voyage together through the mystical universe of cloud-native, on the back burner for a little while. Now now, of course that does not mean that I haven't been exploring further; in fact, quite the contrary.\n\n### So what have I been up to?\nThat's a great question! The past few weeks has actually given me a considerable amount of time to play around with a selection of different projects; some of them more productive than others; but alas, many of them could very happily overviewed on this blog, without having me veer too far off topic. Hopefully over the next few weeks, I will take strides to write some chapters on WTH explaining them. To tease your taste buds, here is a sneak preview of what I have been up to:\n\n- Migration of Kubernetes workloads away from GCP, onto a freshly squeezed kubeadm-based home server 🍋\n- The curious case of the kettle in the kitchen that corrupted the single-node etcd cluster 🔌⚡️\n- Redesigning Kubernetes to be a Highly available, medusa-like god figure 🦹🏻‍♀️\n- Securing Dashboards with OAuth2 Proxy magic 🐇\n\n\n## Enough chit chat, tell me about Velero\nOkay, okay I hear you, listening to my invalid excuses isn't much fun for anyone. But funnily enough, neither is system failure. And what's worse than system failure? I'll tell you for free; system failure with no disaster recovery solution! No disaster recovery solution, mitigation, or protection, for the kubernetes empire that you have worked tirelessly to setup over many months, if not years. But this begs the question; if your workloads are running in ephemeral containers, why not treat your cluster as an ephemeral beast as well?\n\n### Ephemeral?\nIn the world of cloud native, containers by and large are treated to be ephemeral entities. In essence, this means their lifetime is viewed to be very short, before dying a valiant death. For this reason, data that we want to persist after a said death, to be used by the next container that comes along, is given its own dedicated resource to live in. For Kubernetes, this resource is called a persistent volume (PV), and solves many headaches. Try deploying [Grafana](https://blog.chaosinthe.dev/posts/04-prometheus/) dashboards on Kubernetes without any persistent storage; you'll see what I mean!\n\n\n### And my Kubernetes Manifests... Where are they stored? 💾\nAha! now you're asking some important questions. The Kubernetes [manifests](https://devspace.cloud/docs/cli/deployment/kubernetes-manifests/what-are-manifests), are a big stack of yaml files that are presented to the API server. They describe the what, when, how and why of every application running on the cluster, and are stored on a database called [etcd](https://etcd.io/). Without going into this too deeply (I shall save it for another instalment), this a distributed, reliable key-value store; that is accessible cluster-wide. Due to its distributed nature, etcd usually runs in a cluster model of multiple nodes; just like kubernetes. Most commonly, this cluster is set up as a selection of docker containers. Containers everywhere!\n\nSo what happens when you have a single node etcd cluster that has its data corrupted? What happens when the power goes out in your house, and you power your cluster back on to find that your etcd node isn't responding? Well, of course i'm talking from experience, so I can tell you. You cry for a while, and then get up and say; looks like we'll have to just build all over again.\n\n![sand castle](/img/05-Velero/sandcastle.gif \"what happened to my old cluster? 😭\")\n\n### Planning for the inevitable\nWell guess what, in the world of Kubernetes, disaster recovery is not something you should think about on day 2, or day 1... it should be thought out and implemented on day 0. The beauty of treating your containers as ephemeral, is that they can fail relatively frequently, and kubernetes will spin up new ones to take their place; mounting the persistent data in the appropriate places. But as highlighted by the etcd anecdote... my cluster would maybe benefit from taking some inspiration from this 'live fast, die young' attitude that the containers it runs have adopted. Its about time we designed our cluster with failure in mind. Wouldn't it be great to have our Kubernetes resources declaratively backed up in an automated fashion. Sounds great! Well... I hear you thinking \"How do I do that?\"... Velero, take centre stage.\n\n\n## Please don't you rock my boat ⛵️\n\n{{< figure src=\"/img/05-Velero/velero.png\">}}\n\nSo we have deployed our highly-available kubernetes cluster; and we stand triumphantly over our containerised splendor... 3 master nodes, ready to serve our army of workers deployed beneath them, whatever the weather. But just in case our cluster can't quite handle the storm, let [Velero](https://velero.io) be your vessel to guide you through.\n\nGiving you the capability to schedule automatic backups at recurring intervals, you can direct this tool to store a copy of whatever Kubernetes resource you desire. Whether it be persistent volumes, all namespaces, specific namespaces, the whole cluster with every nook and cranny; you name it, you can do it. The tool then enables the user to restore these resources back to the cluster at any time. The tool also supports the migration of these resources to other clusters, so you can save yourself the headache of starting from scratch with every new kubernetes instance. \n\n### But where are those backups going? 🤔\nGood question. These backups are capable of going to a selection of supported object stores, from an array of public cloud and on-premise storage providers. These include AWS S3, Google Cloud Storage, Portworx and OpenEBS. What intrigued me most is, some third-party S3-compatible object store providers also work. So I was able to set this up to for my [Minio](https://min.io/), and avoid those nasty public cloud prices 🤭.\n\n### So...\nIt sounds like this is the solution to all our problems! So how do we use it? Does it work as expected?... Lets find out.\n\n## Time to give it a whirl 🌀\nSo if you have a look at the [overview](https://velero.io/docs/v1.3.2/index.html) documentation, we can see that Velero uses a client-server architecture, deploying a server that runs on the cluster upon install, after a client binary has been setup on the users local machine.\n\nThe basic install shows us that we can simply go ahead and install Velero on any machine that has kubectl access to the cluster you want to backup. I used MacOS, so installed the Velero client tool with the [brew](https://brew.sh/) package manager. Otherwise, the [latest release](https://github.com/vmware-tanzu/velero/releases/latest) tarball for your platform can be downloaded from Github.\n\nFrom there, you need to setup and configure the object store, choosing from the list of providers mentioned above. I used minio, which provides AWS S3 compatible storage.\n\nYou will then need to perform a `velero install` command from your chosen client, with added parameters that describe your object store location. In my case the `install` command with flags looked like the following:\n\n```console\nchaointhecrd@home:~$ velero install \\    \n    --provider aws \\ # name of provider\n    --plugins velero/velero-plugin-for-aws:v1.0.0 \\ # the plugin velero needs to use for minio\n    --bucket velero \\ # the name of the minio bucket\n    --secret-file ./credentials-velero \\ # the credentials for the minio server to be stored in a secret\n    --backup-location-config region=minio,s3ForcePathStyle=\"true\",s3Url=http://192.168.0.210:9000 # specifying the location of the bucket (region and IP)\n```\n\n### Success! Now what to backup first...\n\nSo now there should be a namespace on the cluster called `velero`, and the command `velero get backup-locations` should list the object store of your choosing 😎.\n\nNow this is where things get really slick. So we need something to backup that will test the power this tool really wields, right? Well I thought to myself; how about that [Weave Scope](https://www.weave.works/oss/scope/) namespace I have lying on my cluster, that I haven't really had the time to mess with yet. Sounds good. worst case; no important config lost 🙂.\n\n#### 1. Creating the backup before wreaking havoc 🧨\nAs seen in the animation below, creating the backup is a simple case of telling the client: the name of the backup, and what resources should be included within it. Once this has been carried out, you should be notified that your backup request has been submitted, hurrah! You can then call `velero get backups` to check that it has completed successfully. Bare in mind that the time to backup after submission will depend on the size of the resources being backed up, as well as the network connection to the object store.\n\nOnce the backup is shown as `Completed`, you can go ahead and start creating problems for yourself. `kubectl scale deployment chaos-monkeys --replicas=1000` begins to ring in your eardrums 😼.\n\n{{< figure src=\"/img/05-Velero/velero-backup.gif\">}}\n\n\n```console\nchaosinthecrd@home:~$ velero create backup weave --include-namespaces weave \n# creates the backup\nchaosinthecrd@home:~$ velero get backups\n# fetches the backups, and shows their status\nchaosinthecrd@home:~$ kubectl delete ns weave\n# deletes the namespace... let the chaos begin\n```\n#### 2. Don't panic, and fall back on Velero 🙆‍♂️\nSo we've deleted the namespace, its time to panic. In fact no, it certainly is not time to panic. You were cunning, and planned for disaster on day 0, rather than day 2! Lets make the magic happen.\n\nAs shown in the animation below, I have lost the namespace `weave`, and if I don't get this sorted now; I will be crying myself to sleep, knowing that my users are unable to view the cluster resources zipping around in real time (don't worry, i'll do a post on Scope at some point; it's really cool).\n\nFear not! We created our backup with Velero, and we're not afraid ot use it. A simple `velero restore create` command is all it takes; and before you know it... look! Your namespace is right back where you left it! No `CrashLoopBackoffs`,`Pending` or `Error` pod statuses to worry about here 👌. \n\n{{< figure src=\"/img/05-Velero/velero-restore.gif\">}}\n\n```console\nchaosinthecrd@home:~$ velero restore create --from-backup weave\n# All we need to get 'backup' and running 😏\n```\n\n## Wrapping up\n\nSo, thank you for following along my anecdotal overview of Velero, and how I managed to stumble upon a truly magnificent tool, that has already saved my bacon a couple of times. The best part is that I have only scratched the surface of what Velero is capable of, and I will leave it to you with regards to taking your disaster recovery journey further into the abyss ✨.\n\nAs is tradition with these posts, I have chosen a video that would be worth watching if you want to dive further into the topic in a more practical fashion - check out the TGI Kubernetes Episode at the bottom of the page. It's definitely worth a watch.\n\nFinally, a big thank you to members of the Velero team that helped me with some of the finer details within this post. I would also like to shout out a podcast hosted by one of the Engineers for Velero, Carlisia Campos. [The Podlets](https://www.youtube.com/playlist?list=PL7bmigfV0EqSh-btGOy8BLG3lsF0ylfZ-) is a weekly video podcast, where Carlisia and guests explore cloud native, one buzzword at a time. \n\n{{< youtube tj5Ey2bHsfM >}}\n",
      "html": "<p>The open source tool that makes backing up your Kubernetes Cluster plain sailing!</p>\n<p>Well surprise surprise, it looks like I'm back! Not at all the length of time that I was planning to be away for, but certain events (that I'm sure you will not want to spend another minute hearing about) led me to put our curious voyage together through the mystical universe of cloud-native, on the back burner for a little while. Now now, of course that does not mean that I haven't been exploring further; in fact, quite the contrary.</p>\n<h3>So what have I been up to?</h3>\n<p>That's a great question! The past few weeks has actually given me a considerable amount of time to play around with a selection of different projects; some of them more productive than others; but alas, many of them could very happily overviewed on this blog, without having me veer too far off topic. Hopefully over the next few weeks, I will take strides to write some chapters on WTH explaining them. To tease your taste buds, here is a sneak preview of what I have been up to:</p>\n<ul>\n<li>Migration of Kubernetes workloads away from GCP, onto a freshly squeezed kubeadm-based home server 🍋</li>\n<li>The curious case of the kettle in the kitchen that corrupted the single-node etcd cluster 🔌⚡️</li>\n<li>Redesigning Kubernetes to be a Highly available, medusa-like god figure 🦹🏻‍♀️</li>\n<li>Securing Dashboards with OAuth2 Proxy magic 🐇</li>\n</ul>\n<h2>Enough chit chat, tell me about Velero</h2>\n<p>Okay, okay I hear you, listening to my invalid excuses isn't much fun for anyone. But funnily enough, neither is system failure. And what's worse than system failure? I'll tell you for free; system failure with no disaster recovery solution! No disaster recovery solution, mitigation, or protection, for the kubernetes empire that you have worked tirelessly to setup over many months, if not years. But this begs the question; if your workloads are running in ephemeral containers, why not treat your cluster as an ephemeral beast as well?</p>\n<h3>Ephemeral?</h3>\n<p>In the world of cloud native, containers by and large are treated to be ephemeral entities. In essence, this means their lifetime is viewed to be very short, before dying a valiant death. For this reason, data that we want to persist after a said death, to be used by the next container that comes along, is given its own dedicated resource to live in. For Kubernetes, this resource is called a persistent volume (PV), and solves many headaches. Try deploying <a href=\"https://blog.chaosinthe.dev/posts/04-prometheus/\">Grafana</a> dashboards on Kubernetes without any persistent storage; you'll see what I mean!</p>\n<h3>And my Kubernetes Manifests... Where are they stored? 💾</h3>\n<p>Aha! now you're asking some important questions. The Kubernetes <a href=\"https://devspace.cloud/docs/cli/deployment/kubernetes-manifests/what-are-manifests\">manifests</a>, are a big stack of yaml files that are presented to the API server. They describe the what, when, how and why of every application running on the cluster, and are stored on a database called <a href=\"https://etcd.io/\">etcd</a>. Without going into this too deeply (I shall save it for another instalment), this a distributed, reliable key-value store; that is accessible cluster-wide. Due to its distributed nature, etcd usually runs in a cluster model of multiple nodes; just like kubernetes. Most commonly, this cluster is set up as a selection of docker containers. Containers everywhere!</p>\n<p>So what happens when you have a single node etcd cluster that has its data corrupted? What happens when the power goes out in your house, and you power your cluster back on to find that your etcd node isn't responding? Well, of course i'm talking from experience, so I can tell you. You cry for a while, and then get up and say; looks like we'll have to just build all over again.</p>\n<p><img src=\"/img/05-Velero/sandcastle.gif\" alt=\"sand castle\" title=\"what happened to my old cluster? 😭\"></p>\n<h3>Planning for the inevitable</h3>\n<p>Well guess what, in the world of Kubernetes, disaster recovery is not something you should think about on day 2, or day 1... it should be thought out and implemented on day 0. The beauty of treating your containers as ephemeral, is that they can fail relatively frequently, and kubernetes will spin up new ones to take their place; mounting the persistent data in the appropriate places. But as highlighted by the etcd anecdote... my cluster would maybe benefit from taking some inspiration from this 'live fast, die young' attitude that the containers it runs have adopted. Its about time we designed our cluster with failure in mind. Wouldn't it be great to have our Kubernetes resources declaratively backed up in an automated fashion. Sounds great! Well... I hear you thinking \"How do I do that?\"... Velero, take centre stage.</p>\n<h2>Please don't you rock my boat ⛵️</h2>\n<p>{{&#x3C; figure src=\"/img/05-Velero/velero.png\">}}</p>\n<p>So we have deployed our highly-available kubernetes cluster; and we stand triumphantly over our containerised splendor... 3 master nodes, ready to serve our army of workers deployed beneath them, whatever the weather. But just in case our cluster can't quite handle the storm, let <a href=\"https://velero.io\">Velero</a> be your vessel to guide you through.</p>\n<p>Giving you the capability to schedule automatic backups at recurring intervals, you can direct this tool to store a copy of whatever Kubernetes resource you desire. Whether it be persistent volumes, all namespaces, specific namespaces, the whole cluster with every nook and cranny; you name it, you can do it. The tool then enables the user to restore these resources back to the cluster at any time. The tool also supports the migration of these resources to other clusters, so you can save yourself the headache of starting from scratch with every new kubernetes instance.</p>\n<h3>But where are those backups going? 🤔</h3>\n<p>Good question. These backups are capable of going to a selection of supported object stores, from an array of public cloud and on-premise storage providers. These include AWS S3, Google Cloud Storage, Portworx and OpenEBS. What intrigued me most is, some third-party S3-compatible object store providers also work. So I was able to set this up to for my <a href=\"https://min.io/\">Minio</a>, and avoid those nasty public cloud prices 🤭.</p>\n<h3>So...</h3>\n<p>It sounds like this is the solution to all our problems! So how do we use it? Does it work as expected?... Lets find out.</p>\n<h2>Time to give it a whirl 🌀</h2>\n<p>So if you have a look at the <a href=\"https://velero.io/docs/v1.3.2/index.html\">overview</a> documentation, we can see that Velero uses a client-server architecture, deploying a server that runs on the cluster upon install, after a client binary has been setup on the users local machine.</p>\n<p>The basic install shows us that we can simply go ahead and install Velero on any machine that has kubectl access to the cluster you want to backup. I used MacOS, so installed the Velero client tool with the <a href=\"https://brew.sh/\">brew</a> package manager. Otherwise, the <a href=\"https://github.com/vmware-tanzu/velero/releases/latest\">latest release</a> tarball for your platform can be downloaded from Github.</p>\n<p>From there, you need to setup and configure the object store, choosing from the list of providers mentioned above. I used minio, which provides AWS S3 compatible storage.</p>\n<p>You will then need to perform a <code>velero install</code> command from your chosen client, with added parameters that describe your object store location. In my case the <code>install</code> command with flags looked like the following:</p>\n<pre><code class=\"language-console\">chaointhecrd@home:~$ velero install \\    \n    --provider aws \\ # name of provider\n    --plugins velero/velero-plugin-for-aws:v1.0.0 \\ # the plugin velero needs to use for minio\n    --bucket velero \\ # the name of the minio bucket\n    --secret-file ./credentials-velero \\ # the credentials for the minio server to be stored in a secret\n    --backup-location-config region=minio,s3ForcePathStyle=\"true\",s3Url=http://192.168.0.210:9000 # specifying the location of the bucket (region and IP)\n</code></pre>\n<h3>Success! Now what to backup first...</h3>\n<p>So now there should be a namespace on the cluster called <code>velero</code>, and the command <code>velero get backup-locations</code> should list the object store of your choosing 😎.</p>\n<p>Now this is where things get really slick. So we need something to backup that will test the power this tool really wields, right? Well I thought to myself; how about that <a href=\"https://www.weave.works/oss/scope/\">Weave Scope</a> namespace I have lying on my cluster, that I haven't really had the time to mess with yet. Sounds good. worst case; no important config lost 🙂.</p>\n<h4>1. Creating the backup before wreaking havoc 🧨</h4>\n<p>As seen in the animation below, creating the backup is a simple case of telling the client: the name of the backup, and what resources should be included within it. Once this has been carried out, you should be notified that your backup request has been submitted, hurrah! You can then call <code>velero get backups</code> to check that it has completed successfully. Bare in mind that the time to backup after submission will depend on the size of the resources being backed up, as well as the network connection to the object store.</p>\n<p>Once the backup is shown as <code>Completed</code>, you can go ahead and start creating problems for yourself. <code>kubectl scale deployment chaos-monkeys --replicas=1000</code> begins to ring in your eardrums 😼.</p>\n<p>{{&#x3C; figure src=\"/img/05-Velero/velero-backup.gif\">}}</p>\n<pre><code class=\"language-console\">chaosinthecrd@home:~$ velero create backup weave --include-namespaces weave \n# creates the backup\nchaosinthecrd@home:~$ velero get backups\n# fetches the backups, and shows their status\nchaosinthecrd@home:~$ kubectl delete ns weave\n# deletes the namespace... let the chaos begin\n</code></pre>\n<h4>2. Don't panic, and fall back on Velero 🙆‍♂️</h4>\n<p>So we've deleted the namespace, its time to panic. In fact no, it certainly is not time to panic. You were cunning, and planned for disaster on day 0, rather than day 2! Lets make the magic happen.</p>\n<p>As shown in the animation below, I have lost the namespace <code>weave</code>, and if I don't get this sorted now; I will be crying myself to sleep, knowing that my users are unable to view the cluster resources zipping around in real time (don't worry, i'll do a post on Scope at some point; it's really cool).</p>\n<p>Fear not! We created our backup with Velero, and we're not afraid ot use it. A simple <code>velero restore create</code> command is all it takes; and before you know it... look! Your namespace is right back where you left it! No <code>CrashLoopBackoffs</code>,<code>Pending</code> or <code>Error</code> pod statuses to worry about here 👌.</p>\n<p>{{&#x3C; figure src=\"/img/05-Velero/velero-restore.gif\">}}</p>\n<pre><code class=\"language-console\">chaosinthecrd@home:~$ velero restore create --from-backup weave\n# All we need to get 'backup' and running 😏\n</code></pre>\n<h2>Wrapping up</h2>\n<p>So, thank you for following along my anecdotal overview of Velero, and how I managed to stumble upon a truly magnificent tool, that has already saved my bacon a couple of times. The best part is that I have only scratched the surface of what Velero is capable of, and I will leave it to you with regards to taking your disaster recovery journey further into the abyss ✨.</p>\n<p>As is tradition with these posts, I have chosen a video that would be worth watching if you want to dive further into the topic in a more practical fashion - check out the TGI Kubernetes Episode at the bottom of the page. It's definitely worth a watch.</p>\n<p>Finally, a big thank you to members of the Velero team that helped me with some of the finer details within this post. I would also like to shout out a podcast hosted by one of the Engineers for Velero, Carlisia Campos. <a href=\"https://www.youtube.com/playlist?list=PL7bmigfV0EqSh-btGOy8BLG3lsF0ylfZ-\">The Podlets</a> is a weekly video podcast, where Carlisia and guests explore cloud native, one buzzword at a time.</p>\n<p>{{&#x3C; youtube tj5Ey2bHsfM >}}</p>"
    },
    "_id": "blog/05-Velero.md",
    "_raw": {
      "sourceFilePath": "blog/05-Velero.md",
      "sourceFileName": "05-Velero.md",
      "sourceFileDir": "blog",
      "contentType": "markdown",
      "flattenedPath": "blog/05-Velero"
    },
    "type": "Doc"
  },
  {
    "title": "Build your own Kubernetes-based Boutique",
    "body": {
      "raw": "\nSo you want to commandeer your very own kubernetes vessel... but don't know where to start? Look no further.\n<!--more-->\n\nOkay, so I agree. Kubernetes is an exciting concept for those interested in the enterprise computing world and unless you've been living under a rock for the past year, you have probably heard the name thrown around left, right and centre. In fact, this blog on its own does a pretty good job that. You then begin to delve into the documentation, which talks about the 'microservice architecture' way of life and you start to think, \"What the Hell? How am I meant to just quickly develop my own microservices for the sake of trying out this platform?\". Well this is how I felt, but unfortunately I didn't stumble upon a blog post like this that will now show you a fun way that you can try the fundamentals out for yourself. \n\n\n#### What ingredients do I need for this exercise?\nAll that is required is a google account with either some free credit for [Google Cloud](https://cloud.google.com/free), or a bank card attached. Not to worry though, the cost over the time required for the exercise should be no more than $5. It would also be handy if you had your own unique domain name, but this isn't crucial.\n\n\n![bargain](/img/06-boutique/bargain.gif \"if you're like me, value for money is key\")\nThe blog posts are only just the beginning...\n<!--more-->\n\n\n## Let's deploy an Online Boutique\nRight, let's begin. The first ingredient that we require on this exciting journey to our publically available shop for the boutique lovers of the world, is a suitably named 'classy' cluster.\n\n{{< figure src=\"/img/06-boutique/gke.png\">}}\n\nAs mentioned in the introduction, we will be making use of Google Cloud and its infamous '[Google Kubernetes Engine](https://cloud.google.com/kubernetes-engine)'. Why Google you ask? Well, there are couple of reasons why I think this is a preferable choice for a beginner user:\n- $300 free credit is redeemable from Google to use on their cloud services, so you can `kube` away to your hearts content for months before paying a penny.\n- GKE is the most 'beginner friendly' and simple enterprise Kubernetes service out there at the moment. In my eyes, it's also the most reliable and finished version of the platform.\n- We could have used a local kubernetes distributions such as [minikube](https://github.com/kubernetes/minikube) or [kind](https://github.com/kubernetes-sigs/kind), but these are not designed for production applications and miss out on some key features.\n\n### Install GCloud-SDK\nOnce you have access to the Google Gloud console using your Google Account, the next step will be to create a project in the UI and to [install and setup the GCloud-SDK](https://cloud.google.com/sdk/install) from the terminal on your machine. This will allow us to configure Google Cloud projects from the CLI; a handy tool when provisioning your first cluster. Once the install has completed, you should be able to type `gcloud init`, to connect to your Google account and select the project you made earlier.\n\nOh, I almost forgot; you'll also need [`kubectl`](https://kubernetes.io/docs/tasks/tools/install-kubectl/). This is a simple binary that will allow us to interact with the kubernetes clusters that we have access to. This is somewhat of the communication layer that you will use for your cluster, once it has been provisioned. One other tool that may also be useful is [`kubectx`](https://github.com/ahmetb/kubectx), which will allow you to switch between kubernetes namespaces with the `kubens` command and the cluster that you want to control, with `kubectx`. Feel free to give it a try!\n\n{{< figure src=\"/img/06-boutique/kubens.gif\">}}\n\n\n### Provision that Cluster 🚀\n\nIt is now the moment we have all been waiting for. We have a Google project to host our boutique, as well as a cli to interface with it. We are now at the stage where our cluster is ready to be born out of the fires of the Google data centre.\n\n```console\ngcloud services enable container.googleapis.com\n# enable the Google Kubernetes Engine service\ngcloud container clusters create classy-cluster \\\n    --enable-autoupgrade \\\n    --enable-autoscaling --min-nodes=3 --max-nodes=10 \\\n    --num-nodes=5 --zone=us-central1-a\n# press the big red button, declaring lift-off!\n```\n<script id=\"asciicast-VOIxw3ECwpqDNwNw3uIWL0Sle\" src=\"https://asciinema.org/a/VOIxw3ECwpqDNwNw3uIWL0Sle.js\" async data-autoplay=\"true\" data-size=\"small\" cols=\"100\"></script>\n\nAbove you can see the output you should see in your terminal window upon calling these commands (I can only apologise for the scaling, but it shows you what to expect). As you can see, it finishes with the output of `kubeconfig entry generated for classy-cluster`. Fantastic news! Your cluster should now be addressable with the `kubectl get nodes` command, which lists the 5 nodes that we created. We're off to the races.\n\n\n![rumble](/img/06-boutique/rumble.gif \"Let's get ready to kubectllll\")\n\n### Time to get Boujie\n{{< figure src=\"/img/06-boutique/boutique.svg\">}}\n\nEarlier in the post, I referred to an '[Online Boutique](https://github.com/GoogleCloudPlatform/microservices-demo/)', that is deployable on Kubernetes with a few simple steps. Well, this is in fact a demo application for Kubernetes, consisting of no less than 10 separate microservices. Once deployed, you can use the app to browse through some imaginary items, before adding them to a cart and purchasing. The best part is that on GKE, it is super easy to deploy, which makes it perfect for learning purposes.\n\n<figure>\n<img src=\"/img/06-boutique/architecture.png\" />\n<figcaption>\n<h4>What the boutique looks like under the hood.</h4>\n</figcaption>\n</figure>\n\n![architecture](/img/06-boutique/architecture.png \"What the boutique looks like under the hood.\")\n\nIn order to deploy this application, we must first perform a `git clone` of the github repository, so that we can save a copy of the required kubernetes manifests. This file, written in [yaml](https://blog.stackpath.com/yaml/), instructs to the kubernetes api-server which containers to run, where it can find them, as well as a selection of other parameters such as the ports to be used for the services, the resource requests/limits (cpu and memory) and much more. After cloning, navigate to the 'release' directory, and open the `kubernetes-manifests.yaml` file, to take a look at the many kinds of declarations it features. This is the file we will be passing to the cluster with kubectl in a moment, so keep hold of it.\n\nNow that we have our manifests at the ready, we must now create a [namespace](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/). These are siphoned off areas of the cluster, intended to organise separate clusters and development teams that are working at the same time. liken them to rooms in a building, or sections in a library. By calling `kubectl create namespace boutique`, we can create a special little place for our application to sit. If you installed the `kubectx` application, the `kubens` command will come in handy here (e.g. `kubens boutique`). Otherwise, you can type something like `kubectl config set-context --current --namespace=boutique`, to switch to the `boutique` namespace using `kubectl`.\n\nFinally, let's go ahead and deploy our application on the cluster with the following command:\n\n```console\nkubectl apply -f kubernetes-manifests.yaml \n# and we're off!\n```\n\n### Checking that we're Golden\nyou should see a list of terminal outputs, informing you that the resources declared in the manifests are being created in the namespace that kubectl is looking at. The command `kubectl get pods` should bring up all the pods that have been deployed for our application. After a minute or so of the status showing `ContainerCreating`, they should be up and running.\n\n**Warning:** I experienced some issues with the `loadgenerator` pod, where it would get stuck in a `CrashLoopBackOff`, meaning that it was repeatedly crashing during intilisation. I resolved this by using `kubectl describe loadgenerator-<unique-pod-id>`, which gives some more information about the pod, before performing a `kubectl delete pod`, which will re-instantuate it. This brought the status to the `Running` state we are looking for.\n\n### Lets take a look at our Boutique!\n\nNow that we have all pods up and running, we can call `kubectl get services`, to take a look at the service objects created thanks to our manifest. In the list of objects that it gives back, you should notice a little service called `frontend-external`, with its `TYPE` set to `LoadBalancer`. It should also have an `EXTERNAL-IP` assigned to it. If it is set to `<pending>`, just be patient and use a `watch kubectl get service` command to wait for an IP to be presented to you. What is happening here is that the Kubernetes api-server is communicating with Googles load balancing service, asking for it to assign a unique IP address to this service endpoint. Pretty cool huh? You should now be able to use the `EXTERNAL-IP` provided to view your Boutique. Woo-hoo! We did it!\n\n{{< figure src=\"/img/06-boutique/storefront.png\">}}\n\n\n\n## Hey, check out my store at 35.193.255.113 😬\n**Disclaimer: This section requires that you own a domain name that can be assigned to your cluster.**\n\nYeah, I agree; we're not really going to just give all our pals this IP address on the back of a napkin. Sure, it works... but it doesn't sound very 'boutiquey' if you ask me. I hear you say, 'oh, we can just map the IP with an A record to my domain name on the DNS'. Well, you would be correct, but I have a more effective 'kubernetes way' to do this part. Introducing the beauty of 'Ingress'.\n\nThis was discussed in the very [first blog post](https://blog.chaosinthe.dev/posts/first-posts/) I made, so it may be worth going back and taking a look if you're interested. In esssence though, the ingress controller is a Kubernetes implementation that allows traffic to be directed to specific service endpoints on the cluster, based on parameters such as the domain and extension that has been entered by the user on the client end. This is very useful for handling a tonne of front-end services through one public facing load balancer (LB) IP address.\n\nMy ingress controller of choice is [Contour](https://github.com/projectcontour/contour), and can simply be deployed using the command below. We will also check that the pods for the deployment are running correctly, as well as list the service of the `envoy` daemonset, which is the heart of the contour operation. \n\n```console\nkubectl apply -f https://projectcontour.io/quickstart/contour.yaml\n# deploy contour\nkubectl -n projectcontour get pods\n# check that the pods are running\nkubectl get -n projectcontour service envoy\n# list the envoy service, and its LB IP address\n```\n\nWhen you call the final command, the public IP should be shown for envoy, which is where you want to point your domain name to. Once you have done this, typing `host my-k8s-boutique.net` with the respective domain should give back the IP of the envoy service. Bare in mind that this may take a little while to update, so don't get impatient like I often do!\n\nFinally, we can create an ingress manifest, which declares an ingress resource for contour to take note of, giving it the information it needs in order for the traffic of our domain to be forwarded on to the service. A quick `kubectl -f boutique-ingress.yaml` should get this baby up and running. And as if by magic, we can view our boutique in the web browser through our domain! Now you can flex to your friends with your very own online boutique without repeating the IP to them 34 times. Even though you can't actually buy anything 🤣.\n\n```yaml\napiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: contour\n  name: frontend-external\n  labels:\n    app: frontend-external\nspec:\n  rules:\n  - host: my-k8s-boutique.net   # Change this to your domain!\n  backend:\n    serviceName: frontend-external\n    servicePort: 80\n```\n\n## Persistence is a Virtue\nSo if you're still with me at this point, I applaud your efforts. While this is a fairly straight forward project, it is still a lot of content to take in at once.\n\nWhile digging around our newly christened boutique store, you might have noticed the shopping basket. Sure, looks great; but what happens if the micro-service pod responsible for this functionality dies during a customer shopping spree. **Remember**, pods are designed to be ephemeral, meaning they are not expected to live very long. If you fill the basket with items and then carry out the command `kubectl delete pods -l app=redis-cart`, the boutique should show some error messages while a new 'redis-cart' pod is being created, before becoming available again. But you'll notice, the items you added to the basket are now gone! How inconvenient. \n\nThis problem occurs because the pod has not been assigned a 'persistent-volume' to store data that will survive the pods lifecycle. This is a resource that maps to a mountpoint on a physical disk such as [Persistent Disks](https://cloud.google.com/kubernetes-engine/docs/concepts/persistent-volumes) that are used by Google Compute Engine (GCE). So how do we do this to ensure maximum boutiqueness? All that's needed is a short yaml file declaring a request for the storage object, followed by a reference to it in the original `kubernetes-manifests.yaml` file for the boutique.\n\nThe yaml below shows the persistent volume claim manifest. This is a request to a 'storage class' provider to give the cluster some storage of a specified size. you can view the storage class providers by typing `kubectl get storageclasses`.\n\n```yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: redis-cart\n  annotations:\n    volume.beta.kubernetes.io/storage-class: standard\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n```\n\nAs you can see above, I have requested a persistent volume called 'redis-cart', using the storage class 'standard', which is the storage class installed by default in GKE for using Persistent Disks in GCE. The 'ReadWriteOnce' declaration just means that it can only be mounted as read-write by a single node. This is the default mode and will work for this scenario. I have requested 10gb of storage, which is also plenty for this example. As usual, the `kubectl apply -f redis-cart-pvc.yaml` command is enough to get it attached to the cluster. We can check that the volume was created by checking for the `BOUND` status upon calling `kubectl get pvc`.\n\n<figure>\n<img src=\"/img/06-boutique/persistentvolume.png\" />\n<figcaption>\n<h4>The persistent volume, as seen in the Google Cloud console</h4>\n</figcaption>\n</figure>\n\n\n![architecture](/img/06-boutique/persistentvolume.png \"The persistent volume, as seen in the Google Cloud Console.\")\n\n\nNow to let the redis-cart deployment make use of this prime real-estate, we need to edit our original `kubernetes-manifests.yaml`. There are many objects in this file that we don't need to touch, but the section in question can be seen below, with the appropriate edits already in place. You will notice that at the bottom under `volumes:`, my yaml states a `persistentVolumeClaim`, as opposed to the original `EmptyDir`. This is where we need to set it to the name of our PV `redis-cart`, before saving the yaml file.\n\n```yaml\n### Changes made to Redis Cart so cart data is saved to PV ###\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-cart\nspec:\n  selector:\n    matchLabels:\n      app: redis-cart\n  template:\n    metadata:\n      labels:\n        app: redis-cart\n    spec:\n      containers:\n      - name: redis\n        image: redis:alpine\n        ports:\n        - containerPort: 6379\n        readinessProbe:\n          periodSeconds: 5\n          tcpSocket:\n            port: 6379\n        livenessProbe:\n          periodSeconds: 5\n          tcpSocket:\n            port: 6379\n        volumeMounts:\n        - mountPath: /data\n          name: redis-data\n        resources:\n          limits:\n            memory: 256Mi\n            cpu: 125m\n          requests:\n            cpu: 70m\n            memory: 0Mi\n      volumes:                  # Where we want to edit!\n      - name: redis-data\n        persistentVolumeClaim:\n          claimName: redis-cart\n```\n\nNow finally we are ready to go ahead and call our final `kubectl apply -f kubernetes-manifests.yaml` to do what seemed unthinkable only minutes ago. You have now attached persistent storage to your redis cart! A quick call of `kubectl get pods` will show the pod in a running state. You can then add items to the basket and try deleting the pod. Once it comes back up, your redis database is back up off the canvas 🥊.\n\n## Finishing Up (Don't forget to delete your cluster!)\n\nAll I can say after that one hell of a slog is congratulations for completing your first ever boutique quality Kubernetes project! We have taken a look into what is required to front up a public-cloud based cluster, as well as the initial steps that are taken to deploy an application using `kubectl`, before making it publically available.\n\nNow that we have come to the end of this post, you might want to delete the cluster to ensure you save your pennies for the next exciting run in with Google Cloud. If you want to take things a step further, I would suggest that you maybe look into securing your application with HTTPS traffic. For this you will need a TLS certificate, which can be achieved with ease, thanks to the [cert-manager](https://github.com/jetstack/cert-manager) certificate management controller. Past that, you could maybe even take a look at creating a Grafana dashboard that monitors users navigating the site using [Prometheus](https://blog.chaosinthe.dev/posts/04-prometheus/) to scrap metrics. Who knows, the world is your oyster!\n\nSo, without further ado, let me sign off for this latest post, wishing you all the best wherever you are. Oh yes, without forgetting the command to kill the cluster. Cheerio!\n\n```console\ngcloud container clusters delete classy-cluster 👋👋👋\n```\n\n\n\n\n",
      "html": "<p>So you want to commandeer your very own kubernetes vessel... but don't know where to start? Look no further.</p>\n<p>Okay, so I agree. Kubernetes is an exciting concept for those interested in the enterprise computing world and unless you've been living under a rock for the past year, you have probably heard the name thrown around left, right and centre. In fact, this blog on its own does a pretty good job that. You then begin to delve into the documentation, which talks about the 'microservice architecture' way of life and you start to think, \"What the Hell? How am I meant to just quickly develop my own microservices for the sake of trying out this platform?\". Well this is how I felt, but unfortunately I didn't stumble upon a blog post like this that will now show you a fun way that you can try the fundamentals out for yourself.</p>\n<h4>What ingredients do I need for this exercise?</h4>\n<p>All that is required is a google account with either some free credit for <a href=\"https://cloud.google.com/free\">Google Cloud</a>, or a bank card attached. Not to worry though, the cost over the time required for the exercise should be no more than $5. It would also be handy if you had your own unique domain name, but this isn't crucial.</p>\n<p><img src=\"/img/06-boutique/bargain.gif\" alt=\"bargain\" title=\"if you&#x27;re like me, value for money is key\">\nThe blog posts are only just the beginning...</p>\n<h2>Let's deploy an Online Boutique</h2>\n<p>Right, let's begin. The first ingredient that we require on this exciting journey to our publically available shop for the boutique lovers of the world, is a suitably named 'classy' cluster.</p>\n<p>{{&#x3C; figure src=\"/img/06-boutique/gke.png\">}}</p>\n<p>As mentioned in the introduction, we will be making use of Google Cloud and its infamous '<a href=\"https://cloud.google.com/kubernetes-engine\">Google Kubernetes Engine</a>'. Why Google you ask? Well, there are couple of reasons why I think this is a preferable choice for a beginner user:</p>\n<ul>\n<li>$300 free credit is redeemable from Google to use on their cloud services, so you can <code>kube</code> away to your hearts content for months before paying a penny.</li>\n<li>GKE is the most 'beginner friendly' and simple enterprise Kubernetes service out there at the moment. In my eyes, it's also the most reliable and finished version of the platform.</li>\n<li>We could have used a local kubernetes distributions such as <a href=\"https://github.com/kubernetes/minikube\">minikube</a> or <a href=\"https://github.com/kubernetes-sigs/kind\">kind</a>, but these are not designed for production applications and miss out on some key features.</li>\n</ul>\n<h3>Install GCloud-SDK</h3>\n<p>Once you have access to the Google Gloud console using your Google Account, the next step will be to create a project in the UI and to <a href=\"https://cloud.google.com/sdk/install\">install and setup the GCloud-SDK</a> from the terminal on your machine. This will allow us to configure Google Cloud projects from the CLI; a handy tool when provisioning your first cluster. Once the install has completed, you should be able to type <code>gcloud init</code>, to connect to your Google account and select the project you made earlier.</p>\n<p>Oh, I almost forgot; you'll also need <a href=\"https://kubernetes.io/docs/tasks/tools/install-kubectl/\"><code>kubectl</code></a>. This is a simple binary that will allow us to interact with the kubernetes clusters that we have access to. This is somewhat of the communication layer that you will use for your cluster, once it has been provisioned. One other tool that may also be useful is <a href=\"https://github.com/ahmetb/kubectx\"><code>kubectx</code></a>, which will allow you to switch between kubernetes namespaces with the <code>kubens</code> command and the cluster that you want to control, with <code>kubectx</code>. Feel free to give it a try!</p>\n<p>{{&#x3C; figure src=\"/img/06-boutique/kubens.gif\">}}</p>\n<h3>Provision that Cluster 🚀</h3>\n<p>It is now the moment we have all been waiting for. We have a Google project to host our boutique, as well as a cli to interface with it. We are now at the stage where our cluster is ready to be born out of the fires of the Google data centre.</p>\n<pre><code class=\"language-console\">gcloud services enable container.googleapis.com\n# enable the Google Kubernetes Engine service\ngcloud container clusters create classy-cluster \\\n    --enable-autoupgrade \\\n    --enable-autoscaling --min-nodes=3 --max-nodes=10 \\\n    --num-nodes=5 --zone=us-central1-a\n# press the big red button, declaring lift-off!\n</code></pre>\n<p>Above you can see the output you should see in your terminal window upon calling these commands (I can only apologise for the scaling, but it shows you what to expect). As you can see, it finishes with the output of <code>kubeconfig entry generated for classy-cluster</code>. Fantastic news! Your cluster should now be addressable with the <code>kubectl get nodes</code> command, which lists the 5 nodes that we created. We're off to the races.</p>\n<p><img src=\"/img/06-boutique/rumble.gif\" alt=\"rumble\" title=\"Let&#x27;s get ready to kubectllll\"></p>\n<h3>Time to get Boujie</h3>\n<p>{{&#x3C; figure src=\"/img/06-boutique/boutique.svg\">}}</p>\n<p>Earlier in the post, I referred to an '<a href=\"https://github.com/GoogleCloudPlatform/microservices-demo/\">Online Boutique</a>', that is deployable on Kubernetes with a few simple steps. Well, this is in fact a demo application for Kubernetes, consisting of no less than 10 separate microservices. Once deployed, you can use the app to browse through some imaginary items, before adding them to a cart and purchasing. The best part is that on GKE, it is super easy to deploy, which makes it perfect for learning purposes.</p>\n<p><img src=\"/img/06-boutique/architecture.png\" alt=\"architecture\" title=\"What the boutique looks like under the hood.\"></p>\n<p>In order to deploy this application, we must first perform a <code>git clone</code> of the github repository, so that we can save a copy of the required kubernetes manifests. This file, written in <a href=\"https://blog.stackpath.com/yaml/\">yaml</a>, instructs to the kubernetes api-server which containers to run, where it can find them, as well as a selection of other parameters such as the ports to be used for the services, the resource requests/limits (cpu and memory) and much more. After cloning, navigate to the 'release' directory, and open the <code>kubernetes-manifests.yaml</code> file, to take a look at the many kinds of declarations it features. This is the file we will be passing to the cluster with kubectl in a moment, so keep hold of it.</p>\n<p>Now that we have our manifests at the ready, we must now create a <a href=\"https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/\">namespace</a>. These are siphoned off areas of the cluster, intended to organise separate clusters and development teams that are working at the same time. liken them to rooms in a building, or sections in a library. By calling <code>kubectl create namespace boutique</code>, we can create a special little place for our application to sit. If you installed the <code>kubectx</code> application, the <code>kubens</code> command will come in handy here (e.g. <code>kubens boutique</code>). Otherwise, you can type something like <code>kubectl config set-context --current --namespace=boutique</code>, to switch to the <code>boutique</code> namespace using <code>kubectl</code>.</p>\n<p>Finally, let's go ahead and deploy our application on the cluster with the following command:</p>\n<pre><code class=\"language-console\">kubectl apply -f kubernetes-manifests.yaml \n# and we're off!\n</code></pre>\n<h3>Checking that we're Golden</h3>\n<p>you should see a list of terminal outputs, informing you that the resources declared in the manifests are being created in the namespace that kubectl is looking at. The command <code>kubectl get pods</code> should bring up all the pods that have been deployed for our application. After a minute or so of the status showing <code>ContainerCreating</code>, they should be up and running.</p>\n<p><strong>Warning:</strong> I experienced some issues with the <code>loadgenerator</code> pod, where it would get stuck in a <code>CrashLoopBackOff</code>, meaning that it was repeatedly crashing during intilisation. I resolved this by using <code>kubectl describe loadgenerator-&#x3C;unique-pod-id></code>, which gives some more information about the pod, before performing a <code>kubectl delete pod</code>, which will re-instantuate it. This brought the status to the <code>Running</code> state we are looking for.</p>\n<h3>Lets take a look at our Boutique!</h3>\n<p>Now that we have all pods up and running, we can call <code>kubectl get services</code>, to take a look at the service objects created thanks to our manifest. In the list of objects that it gives back, you should notice a little service called <code>frontend-external</code>, with its <code>TYPE</code> set to <code>LoadBalancer</code>. It should also have an <code>EXTERNAL-IP</code> assigned to it. If it is set to <code>&#x3C;pending></code>, just be patient and use a <code>watch kubectl get service</code> command to wait for an IP to be presented to you. What is happening here is that the Kubernetes api-server is communicating with Googles load balancing service, asking for it to assign a unique IP address to this service endpoint. Pretty cool huh? You should now be able to use the <code>EXTERNAL-IP</code> provided to view your Boutique. Woo-hoo! We did it!</p>\n<p>{{&#x3C; figure src=\"/img/06-boutique/storefront.png\">}}</p>\n<h2>Hey, check out my store at 35.193.255.113 😬</h2>\n<p><strong>Disclaimer: This section requires that you own a domain name that can be assigned to your cluster.</strong></p>\n<p>Yeah, I agree; we're not really going to just give all our pals this IP address on the back of a napkin. Sure, it works... but it doesn't sound very 'boutiquey' if you ask me. I hear you say, 'oh, we can just map the IP with an A record to my domain name on the DNS'. Well, you would be correct, but I have a more effective 'kubernetes way' to do this part. Introducing the beauty of 'Ingress'.</p>\n<p>This was discussed in the very <a href=\"https://blog.chaosinthe.dev/posts/first-posts/\">first blog post</a> I made, so it may be worth going back and taking a look if you're interested. In esssence though, the ingress controller is a Kubernetes implementation that allows traffic to be directed to specific service endpoints on the cluster, based on parameters such as the domain and extension that has been entered by the user on the client end. This is very useful for handling a tonne of front-end services through one public facing load balancer (LB) IP address.</p>\n<p>My ingress controller of choice is <a href=\"https://github.com/projectcontour/contour\">Contour</a>, and can simply be deployed using the command below. We will also check that the pods for the deployment are running correctly, as well as list the service of the <code>envoy</code> daemonset, which is the heart of the contour operation.</p>\n<pre><code class=\"language-console\">kubectl apply -f https://projectcontour.io/quickstart/contour.yaml\n# deploy contour\nkubectl -n projectcontour get pods\n# check that the pods are running\nkubectl get -n projectcontour service envoy\n# list the envoy service, and its LB IP address\n</code></pre>\n<p>When you call the final command, the public IP should be shown for envoy, which is where you want to point your domain name to. Once you have done this, typing <code>host my-k8s-boutique.net</code> with the respective domain should give back the IP of the envoy service. Bare in mind that this may take a little while to update, so don't get impatient like I often do!</p>\n<p>Finally, we can create an ingress manifest, which declares an ingress resource for contour to take note of, giving it the information it needs in order for the traffic of our domain to be forwarded on to the service. A quick <code>kubectl -f boutique-ingress.yaml</code> should get this baby up and running. And as if by magic, we can view our boutique in the web browser through our domain! Now you can flex to your friends with your very own online boutique without repeating the IP to them 34 times. Even though you can't actually buy anything 🤣.</p>\n<pre><code class=\"language-yaml\">apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: contour\n  name: frontend-external\n  labels:\n    app: frontend-external\nspec:\n  rules:\n  - host: my-k8s-boutique.net   # Change this to your domain!\n  backend:\n    serviceName: frontend-external\n    servicePort: 80\n</code></pre>\n<h2>Persistence is a Virtue</h2>\n<p>So if you're still with me at this point, I applaud your efforts. While this is a fairly straight forward project, it is still a lot of content to take in at once.</p>\n<p>While digging around our newly christened boutique store, you might have noticed the shopping basket. Sure, looks great; but what happens if the micro-service pod responsible for this functionality dies during a customer shopping spree. <strong>Remember</strong>, pods are designed to be ephemeral, meaning they are not expected to live very long. If you fill the basket with items and then carry out the command <code>kubectl delete pods -l app=redis-cart</code>, the boutique should show some error messages while a new 'redis-cart' pod is being created, before becoming available again. But you'll notice, the items you added to the basket are now gone! How inconvenient.</p>\n<p>This problem occurs because the pod has not been assigned a 'persistent-volume' to store data that will survive the pods lifecycle. This is a resource that maps to a mountpoint on a physical disk such as <a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/persistent-volumes\">Persistent Disks</a> that are used by Google Compute Engine (GCE). So how do we do this to ensure maximum boutiqueness? All that's needed is a short yaml file declaring a request for the storage object, followed by a reference to it in the original <code>kubernetes-manifests.yaml</code> file for the boutique.</p>\n<p>The yaml below shows the persistent volume claim manifest. This is a request to a 'storage class' provider to give the cluster some storage of a specified size. you can view the storage class providers by typing <code>kubectl get storageclasses</code>.</p>\n<pre><code class=\"language-yaml\">apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: redis-cart\n  annotations:\n    volume.beta.kubernetes.io/storage-class: standard\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n</code></pre>\n<p>As you can see above, I have requested a persistent volume called 'redis-cart', using the storage class 'standard', which is the storage class installed by default in GKE for using Persistent Disks in GCE. The 'ReadWriteOnce' declaration just means that it can only be mounted as read-write by a single node. This is the default mode and will work for this scenario. I have requested 10gb of storage, which is also plenty for this example. As usual, the <code>kubectl apply -f redis-cart-pvc.yaml</code> command is enough to get it attached to the cluster. We can check that the volume was created by checking for the <code>BOUND</code> status upon calling <code>kubectl get pvc</code>.</p>\n<p><img src=\"/img/06-boutique/persistentvolume.png\" alt=\"architecture\" title=\"The persistent volume, as seen in the Google Cloud Console.\"></p>\n<p>Now to let the redis-cart deployment make use of this prime real-estate, we need to edit our original <code>kubernetes-manifests.yaml</code>. There are many objects in this file that we don't need to touch, but the section in question can be seen below, with the appropriate edits already in place. You will notice that at the bottom under <code>volumes:</code>, my yaml states a <code>persistentVolumeClaim</code>, as opposed to the original <code>EmptyDir</code>. This is where we need to set it to the name of our PV <code>redis-cart</code>, before saving the yaml file.</p>\n<pre><code class=\"language-yaml\">### Changes made to Redis Cart so cart data is saved to PV ###\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-cart\nspec:\n  selector:\n    matchLabels:\n      app: redis-cart\n  template:\n    metadata:\n      labels:\n        app: redis-cart\n    spec:\n      containers:\n      - name: redis\n        image: redis:alpine\n        ports:\n        - containerPort: 6379\n        readinessProbe:\n          periodSeconds: 5\n          tcpSocket:\n            port: 6379\n        livenessProbe:\n          periodSeconds: 5\n          tcpSocket:\n            port: 6379\n        volumeMounts:\n        - mountPath: /data\n          name: redis-data\n        resources:\n          limits:\n            memory: 256Mi\n            cpu: 125m\n          requests:\n            cpu: 70m\n            memory: 0Mi\n      volumes:                  # Where we want to edit!\n      - name: redis-data\n        persistentVolumeClaim:\n          claimName: redis-cart\n</code></pre>\n<p>Now finally we are ready to go ahead and call our final <code>kubectl apply -f kubernetes-manifests.yaml</code> to do what seemed unthinkable only minutes ago. You have now attached persistent storage to your redis cart! A quick call of <code>kubectl get pods</code> will show the pod in a running state. You can then add items to the basket and try deleting the pod. Once it comes back up, your redis database is back up off the canvas 🥊.</p>\n<h2>Finishing Up (Don't forget to delete your cluster!)</h2>\n<p>All I can say after that one hell of a slog is congratulations for completing your first ever boutique quality Kubernetes project! We have taken a look into what is required to front up a public-cloud based cluster, as well as the initial steps that are taken to deploy an application using <code>kubectl</code>, before making it publically available.</p>\n<p>Now that we have come to the end of this post, you might want to delete the cluster to ensure you save your pennies for the next exciting run in with Google Cloud. If you want to take things a step further, I would suggest that you maybe look into securing your application with HTTPS traffic. For this you will need a TLS certificate, which can be achieved with ease, thanks to the <a href=\"https://github.com/jetstack/cert-manager\">cert-manager</a> certificate management controller. Past that, you could maybe even take a look at creating a Grafana dashboard that monitors users navigating the site using <a href=\"https://blog.chaosinthe.dev/posts/04-prometheus/\">Prometheus</a> to scrap metrics. Who knows, the world is your oyster!</p>\n<p>So, without further ado, let me sign off for this latest post, wishing you all the best wherever you are. Oh yes, without forgetting the command to kill the cluster. Cheerio!</p>\n<pre><code class=\"language-console\">gcloud container clusters delete classy-cluster 👋👋👋\n</code></pre>"
    },
    "_id": "blog/06-boutique.md",
    "_raw": {
      "sourceFilePath": "blog/06-boutique.md",
      "sourceFileName": "06-boutique.md",
      "sourceFileDir": "blog",
      "contentType": "markdown",
      "flattenedPath": "blog/06-boutique"
    },
    "type": "Doc"
  },
  {
    "title": "No. Don't put your back into it.",
    "body": {
      "raw": "\n![someone asking for back problems](/img/back/back.png \"someone asking for back problems\")\n\n**Note:** I don't know everything about how to prevent back pain from work, I am no expert. This is simply my learnings from my experience. If you disagree with anything written in here, or feel like I am misinformed, please leave a comment on the post.\n\nMy name is Tom. I am 26 years old, I am 6 ft 1 inches tall, and I weigh 86 kilograms (with 0.8 kilograms added on due to too much cheese at christmas). Like 8 out of 10 people in the world on average, I have unfortunately experienced back pain since I was 15 years old.\n\n**How it started**\n\nMy first memory of having a problem was on the rugby pitch. I was in a training session and ran into a [ruck](https://en.wikipedia.org/wiki/Rugby_union_gameplay#Ruck) to defend against invisible opposition. I went into a low position (see below) as I had been instructed since a small child, and all of a sudden I felt a pain that sent me to the floor. It seemed to be coming from the lower back, but it also spread across my glute muscles and it seemed like a knife was being twisted in the very middle of the bottom of my spine. Back then (as is the typical nature of some rugby coaches), I was told that I should either man up or get the hell off the pitch. It was then that I proceeded to hobble (barely) to the nearest building to find somewhere to lie prone until I could figure out my next move. After managing to get home with some assistance, I had a hot bath and slept until the next day. Simple tasks that required a range of movement like putting on socks and shoes were difficult and painful, but this eventually subsided after a week or so (sometimes it can be longer), albeit with a physio session in the middle which really didn't do much to help me understand the problem.\n\n![ruck position](/img/back/ruck.png \"the aforementioned low 'ruck position'\")\n\nThe scenario that I explained above is what I now call a \"flare up\". These \"flare up\"'s have come and gone over the years. It is my belief at least that in my school and university years, they occurred very infrequently (I am only going from memory). However, I have had some periods in my life where the problem just doesn't seem to go away (like the last few months). I have had other times where I have been immobilized in other areas (e.g., front of the leg), and upon inspection of physio I was told that it is all tied into issues with my lower back.\n\n**Entering the world of work**\n\nAt my very first desk based job, I was put through a mandatory ergonomics assessment. What a chore right? Someone came to my desk, and told me that the cool looking chair was wrong, and the ugly looking chair was right (Hell no!). I had the chair height all wrong (this person knows nothing because having it really high is way comfier and I feel like piloting a spaceship) and worst of all; she informed me that a piece of software on my laptop would make a \"ding\" noise every 30 minutes or so to tell me to \"get up and walk around\". She left and I kindly thanked her, before returning the old chair back to my cube, adjusting it to how it was before and fetching the python script from my coworker that stopped the annoying software from making the \"ding\" noise over and over.\n\nDuring my time at this job, I started a bit of a revolution in my personal fitness after hitting a slump from hanging up my rugby boots. I transformed into an avid gym goer (\"hadoken!'), as well as an avid runner (\"run forest!\"). While they eventually subsided, I recall these flare ups posing as a considerable barrier to this transformation at the start. I recall maybe having multiple flare ups in the space of about 6 months. If I had listened to the ergonomic professional, would things have been different? Maybe, maybe not. Anyway what the heck, the pain went away so who cares.\n\n**The next job: An ongoing saga**\n\nFast forward to my next job. On my first day I was flown to Cork in the Republic of Ireland for 6 weeks of ~~drinking~~ training. Down I sat in the conference room with the standard chair (see below) and on the 2nd 8 hour day, around 5 hours in, the pain started. It actually started in my neck this time around, but eventually the problem spread and before I knew it my lower back joined the party. I went to see a physio whilst in Ireland, and I spent the rest of the trip trying to get it back in a state where I wasn't in pain.\n\n![horrid chair](/img/back/chair.png \"The dreaded conference chair\")\n\nUpon arriving back in London after my induction, I had another mandatory assessment. This time around I was more prepared to listen. After all, I had been through a painful time, and this time I wanted to get it right. Unfortunately I was not much more prepared to listen than I had been at my previous employer. However, I began to appreciate the importance of \"ergonomics\". I need to make sure while I slave away at my brand new jobs, that I sit in the \"proper position\". Getting the right chair and the right accessories.\n\n**Solving my problem**\n\nIn order to combat back pain once starting at my current employer, I made investments into home office equipment that I thought would be my saviour. An Expensive chair with a sexy name like \"aeron\" for hefty price tags that would put me in an ergonomic position so I can sit for hours to my heart's content. Couple that with a monitor arm to put my neck at the right height and we are all good right? No slouching, no perching, no sitting with my legs crossed (I can't do that anyhow), these are exactly what I need to be avoiding.\n\n\n![mishter bohnd](/img/back/bond-aeron.jpg \"james bond sat next to a sexy aeron\")\n\n**Or so I thought**\n\nRather unfortunately for me, while the ergonomic chair (and even the standing desk) might have helped me in some ways, the last 6 months have been a slow, slippery slope towards getting to a stage where the pain persisted and became unbearable. Gone were the days where I just took it easy for a week and waited for a reset. I was now at a stage where walking 200 meters to the shop was unbearable, and sitting (or standing) at my desk was something I could only dream of. I endured severe sciatica, which can only be described like electric shocks going down the back of your legs, and muscle spasms which wouldn't stop even if I was lying completely still. For short periods it left me unable to walk. I had no choice but to sign off work.\n\n**How bad was it?**\n\nThis is always a hard one for me to evaluate, but I would rank the few weeks where I was completely immobile as some of the most depressing weeks of my life. Not only can you not do anything, but day to day tasks become difficult.\n\nImpatience reaches an all time high as you feel stupid not being able to get in and out of cars properly, unable to put your socks and shoes on unassisted, and defeated with pain from the smallest of tasks like a short walk into a shop, or a trip upstairs to grab a jumper.\n\nSelf esteem takes a hit too. Don't underestimate what might go through your head when you get hit by something like this for even a few weeks. Will it ever go back to normal? Will I ever be active again? Will my girlfriend get fed up with me if she has to keep helping me like this (she was half fed up with me anyway l-o-l)? You start to wonder how long this storm will last. The reality is that there isn't an answer. For some people, this is a problem that can last years. That can take a toll on an individual.\n\nFinally, your mood and attitude can take a hit. Given I am 26, I suppose it isn't totally unreasonable for one to assume that I am completely able bodied. I should be shaking my hips like many have seen me do on any standard all hands night out, right? There's nothing more defeating than struggling out of a taxi whilst getting out at the hospital to get \"hurry up, hurry up, we are blocking the street\". The fact that the action is so slow and painful is infuriating enough. Getting called a lazy liar for asking the train station steward to let you through the exit gates so you can get to the train easier left me in fits of rage. Being barged in public when I am able bodied is annoying, but when immobile like this left me, it made me furious. Soon enough I was sick of the world and everyone in it.\n\n**Why am I saying all this?**\n\nWell I promise it isn't so people can pat me on the back and tell me it is okay. I am saying this because I want as many people as possible to know that this sucks. It's not a \"oh god yeah my back is sore and it's giving me some grief\", it really is a problem that can leave people immobilized, in some cases with damage that can't actually be properly fixed.\n\n**What is the problem in my case?**\n\nI have a protrusion of a disc in my lower spine (L4-L5). [Discs](https://www.spineuniverse.com/conditions/herniated-disc/disc-protrusion) are jelly like objects that sit between each vertebrae in your spine, acting like shock absorbers. If they protrude (like mine do), they can press into one or some of the many nerves that run down your back, which (trust me) then causes havoc through your nervous system and alarm bells (pain) start to ring.\n\n**What's the solution?**\n\nRight now, I am working on it. If you get yourself in this position, there is no magic pill. The age old  \"Just get some rest\" could well make things worse, but \"just get moving\" can become impossible if the problem leads to great pain and very restricted movement. I had an epidural (or in other words a back injection) of steroids that reduce the pain and irritation in the area, which should in theory leave me more free to perform rehab (which I was already doing pre-flare-up) that has been assigned by my therapist. I am also getting acupuncture done once a week. Realistically, I have been told that unless I build my body to work against the herniation that I have, this problem will repeat over and over and over. The problem is there now and there is little to nothing I can do to fully fix the problem in the mid to long distance future.\n\n**Why is this relevant to you?**\n\nIt simply could be that my problem is that I was handed a crappy set of genes. You're probably not wrong. There are a few people in my family that have struggled with this problem over the years. However none of them have had it so severely (up until my grandparents at least). Could this be because of my career? Well, again I can't say for certain. But I suspect it could well be the case. Time and time again over this last month I have been asked what I do for a living. The response of \"software developer\" has most of the time led to an \"ah yes\", followed by a long discussion on how I practice good desk hygiene. Below are two pieces of advice I was given from professionals along the way, and I hope that they peak your interest.\n\n***There is no such thing as a perfectly ergonomic position***\n\nIf you think your Herman Miller chair is your one way ticket to a full day of working in a seat, I would encourage you to think again. It is considered by many that [prolonged sitting of any kind can lead to the same symptoms](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4152382/#:~:text=Go%20to%3A-,INTRODUCTION,-Low%20back%20pain) that I have experienced over the last few weeks. Tim Cook (CEO of Apple) even said that sitting is the \"[new cancer](https://www.phonearena.com/news/Apple-Park-standing-desks_id105769)\", and stated that standing desks were purchased for each employee at the apple campus. Could you ignore this advice and be just fine? Sure. But I would implore you to read the previous sections that outline the pain these problems cause before deciding whether this is a risk you want to take.\n\nWe all need to be somewhat stationary to do our jobs (unless there is some ingenious new method I have not heard of), so how else can you work? Standing up? Well yes, but again, staying static, even standing for prolonged periods can bring its own problems, especially if you're slouching around, which I have actually found hard to catch myself doing. The key is movement. I have been told now by a couple of professionals that changing positions frequently (literally as frequently as possible) is the best way to go. Sure, sit for a little bit, but switch things up. Stand for an hour or so, move over to the sofa and put your feet up. Most importantly, \"ding!\". Move away from the computer! The annoying software was there for a reason that I can now understand. Take a work call on your phone and walk in the park, allhands while doing chores around the house. This might infuriate some, but unfortunately I don't see any other way of mitigating the risks I have mentioned above.\n\n***Ergonomics aren't completely useless: making sure we are enabled is critical!***\n\nLike many companies out there, I work at a fully remote company. There is no office attendance policy, so instead we make our office the home. Therefore, the days of the ergonomic assessor coming round to the desk have gone. The pre-purchased and approved furniture (that was expensive for a reason) is no more, and the process of making the office a safe place (or not doing anything at all) is now in the hands of the employee. The cheaply made desk furniture that can squeeze into the corner of your bedroom has arisen, as well as cheaply made chairs that do nothing to keep one safe. Even worse, some might find their first month at a new job working from a kitchen table in a wooden chair. What is the protocol in place at your company for a new joiner in such a position? Do you have one?\n\nAll of this made me ask the question, \"is having a safe environment to work no longer the employers responsibility?\". I pondered over this, and it somewhat reminded me of the [Uber workers rights cases](https://www.brownejacobson.com/insights/uber-drivers-entitled-to-workers-rights) of the past. While I work for my employer, should they not be responsible for at least trying to ensure that I am helping myself? While this may not be law, I think that any business should want what is good for their employees. What exactly does that look like? I'm not so sure.\n\nI am lucky enough to be at an employer that gives me a hefty office equipment budget, but after shelling out on a 14\" Macbook Pro, I am left with barely a couple of pennies to spare. \"Well maybe you should have thought before buying an outrageously overpriced machine\" I can hear one say. Well yes, lesson learned. However I do think more could be done within every remote business to help employees take care of their health while they are working, particularly in the area of ergonomics. How exactly this is handled should be up to the specific business, but hopefully you will agree that ensuring an employee can keep themselves healthy while working is more important than the speed and power of their laptop.\n\nLike high visibility jackets and hard hats at a construction site, I believe that employers should have an obligation to ensure that employees are using appropriate equipment before they embark on their working adventure. Like at my first job, the furniture might not be designed by Jony Ive, and it could even be second hand from a previous employer, but it darn should be available to help prevent real problems.\n\n***Please. Just don't over work***\n\nI might have mentioned that I work at a virtual company. Once upon a time, over working would involve being sat in a deserted and dark office, with the lights occasionally turning on when a cleaner walked past. In the remote world, I can slap on some of my favourite tunes, grab a ready meal from the fridge and keep on cracking! Back into my cosy chair I go and more work to be done.\n\nThis doesn't just ruin your social life. It doesn't just burn you out and add to stress (which can lead to physical problems such as back pain). It means you're spending even more time stuck. Not moving, not walking, stretching, running, bending. You're driving yourself towards a world of problems, and trust me, they really hurt.\n",
      "html": "<p><img src=\"/img/back/back.png\" alt=\"someone asking for back problems\" title=\"someone asking for back problems\"></p>\n<p><strong>Note:</strong> I don't know everything about how to prevent back pain from work, I am no expert. This is simply my learnings from my experience. If you disagree with anything written in here, or feel like I am misinformed, please leave a comment on the post.</p>\n<p>My name is Tom. I am 26 years old, I am 6 ft 1 inches tall, and I weigh 86 kilograms (with 0.8 kilograms added on due to too much cheese at christmas). Like 8 out of 10 people in the world on average, I have unfortunately experienced back pain since I was 15 years old.</p>\n<p><strong>How it started</strong></p>\n<p>My first memory of having a problem was on the rugby pitch. I was in a training session and ran into a <a href=\"https://en.wikipedia.org/wiki/Rugby_union_gameplay#Ruck\">ruck</a> to defend against invisible opposition. I went into a low position (see below) as I had been instructed since a small child, and all of a sudden I felt a pain that sent me to the floor. It seemed to be coming from the lower back, but it also spread across my glute muscles and it seemed like a knife was being twisted in the very middle of the bottom of my spine. Back then (as is the typical nature of some rugby coaches), I was told that I should either man up or get the hell off the pitch. It was then that I proceeded to hobble (barely) to the nearest building to find somewhere to lie prone until I could figure out my next move. After managing to get home with some assistance, I had a hot bath and slept until the next day. Simple tasks that required a range of movement like putting on socks and shoes were difficult and painful, but this eventually subsided after a week or so (sometimes it can be longer), albeit with a physio session in the middle which really didn't do much to help me understand the problem.</p>\n<p><img src=\"/img/back/ruck.png\" alt=\"ruck position\" title=\"the aforementioned low &#x27;ruck position&#x27;\"></p>\n<p>The scenario that I explained above is what I now call a \"flare up\". These \"flare up\"'s have come and gone over the years. It is my belief at least that in my school and university years, they occurred very infrequently (I am only going from memory). However, I have had some periods in my life where the problem just doesn't seem to go away (like the last few months). I have had other times where I have been immobilized in other areas (e.g., front of the leg), and upon inspection of physio I was told that it is all tied into issues with my lower back.</p>\n<p><strong>Entering the world of work</strong></p>\n<p>At my very first desk based job, I was put through a mandatory ergonomics assessment. What a chore right? Someone came to my desk, and told me that the cool looking chair was wrong, and the ugly looking chair was right (Hell no!). I had the chair height all wrong (this person knows nothing because having it really high is way comfier and I feel like piloting a spaceship) and worst of all; she informed me that a piece of software on my laptop would make a \"ding\" noise every 30 minutes or so to tell me to \"get up and walk around\". She left and I kindly thanked her, before returning the old chair back to my cube, adjusting it to how it was before and fetching the python script from my coworker that stopped the annoying software from making the \"ding\" noise over and over.</p>\n<p>During my time at this job, I started a bit of a revolution in my personal fitness after hitting a slump from hanging up my rugby boots. I transformed into an avid gym goer (\"hadoken!'), as well as an avid runner (\"run forest!\"). While they eventually subsided, I recall these flare ups posing as a considerable barrier to this transformation at the start. I recall maybe having multiple flare ups in the space of about 6 months. If I had listened to the ergonomic professional, would things have been different? Maybe, maybe not. Anyway what the heck, the pain went away so who cares.</p>\n<p><strong>The next job: An ongoing saga</strong></p>\n<p>Fast forward to my next job. On my first day I was flown to Cork in the Republic of Ireland for 6 weeks of ~~drinking~~ training. Down I sat in the conference room with the standard chair (see below) and on the 2nd 8 hour day, around 5 hours in, the pain started. It actually started in my neck this time around, but eventually the problem spread and before I knew it my lower back joined the party. I went to see a physio whilst in Ireland, and I spent the rest of the trip trying to get it back in a state where I wasn't in pain.</p>\n<p><img src=\"/img/back/chair.png\" alt=\"horrid chair\" title=\"The dreaded conference chair\"></p>\n<p>Upon arriving back in London after my induction, I had another mandatory assessment. This time around I was more prepared to listen. After all, I had been through a painful time, and this time I wanted to get it right. Unfortunately I was not much more prepared to listen than I had been at my previous employer. However, I began to appreciate the importance of \"ergonomics\". I need to make sure while I slave away at my brand new jobs, that I sit in the \"proper position\". Getting the right chair and the right accessories.</p>\n<p><strong>Solving my problem</strong></p>\n<p>In order to combat back pain once starting at my current employer, I made investments into home office equipment that I thought would be my saviour. An Expensive chair with a sexy name like \"aeron\" for hefty price tags that would put me in an ergonomic position so I can sit for hours to my heart's content. Couple that with a monitor arm to put my neck at the right height and we are all good right? No slouching, no perching, no sitting with my legs crossed (I can't do that anyhow), these are exactly what I need to be avoiding.</p>\n<p><img src=\"/img/back/bond-aeron.jpg\" alt=\"mishter bohnd\" title=\"james bond sat next to a sexy aeron\"></p>\n<p><strong>Or so I thought</strong></p>\n<p>Rather unfortunately for me, while the ergonomic chair (and even the standing desk) might have helped me in some ways, the last 6 months have been a slow, slippery slope towards getting to a stage where the pain persisted and became unbearable. Gone were the days where I just took it easy for a week and waited for a reset. I was now at a stage where walking 200 meters to the shop was unbearable, and sitting (or standing) at my desk was something I could only dream of. I endured severe sciatica, which can only be described like electric shocks going down the back of your legs, and muscle spasms which wouldn't stop even if I was lying completely still. For short periods it left me unable to walk. I had no choice but to sign off work.</p>\n<p><strong>How bad was it?</strong></p>\n<p>This is always a hard one for me to evaluate, but I would rank the few weeks where I was completely immobile as some of the most depressing weeks of my life. Not only can you not do anything, but day to day tasks become difficult.</p>\n<p>Impatience reaches an all time high as you feel stupid not being able to get in and out of cars properly, unable to put your socks and shoes on unassisted, and defeated with pain from the smallest of tasks like a short walk into a shop, or a trip upstairs to grab a jumper.</p>\n<p>Self esteem takes a hit too. Don't underestimate what might go through your head when you get hit by something like this for even a few weeks. Will it ever go back to normal? Will I ever be active again? Will my girlfriend get fed up with me if she has to keep helping me like this (she was half fed up with me anyway l-o-l)? You start to wonder how long this storm will last. The reality is that there isn't an answer. For some people, this is a problem that can last years. That can take a toll on an individual.</p>\n<p>Finally, your mood and attitude can take a hit. Given I am 26, I suppose it isn't totally unreasonable for one to assume that I am completely able bodied. I should be shaking my hips like many have seen me do on any standard all hands night out, right? There's nothing more defeating than struggling out of a taxi whilst getting out at the hospital to get \"hurry up, hurry up, we are blocking the street\". The fact that the action is so slow and painful is infuriating enough. Getting called a lazy liar for asking the train station steward to let you through the exit gates so you can get to the train easier left me in fits of rage. Being barged in public when I am able bodied is annoying, but when immobile like this left me, it made me furious. Soon enough I was sick of the world and everyone in it.</p>\n<p><strong>Why am I saying all this?</strong></p>\n<p>Well I promise it isn't so people can pat me on the back and tell me it is okay. I am saying this because I want as many people as possible to know that this sucks. It's not a \"oh god yeah my back is sore and it's giving me some grief\", it really is a problem that can leave people immobilized, in some cases with damage that can't actually be properly fixed.</p>\n<p><strong>What is the problem in my case?</strong></p>\n<p>I have a protrusion of a disc in my lower spine (L4-L5). <a href=\"https://www.spineuniverse.com/conditions/herniated-disc/disc-protrusion\">Discs</a> are jelly like objects that sit between each vertebrae in your spine, acting like shock absorbers. If they protrude (like mine do), they can press into one or some of the many nerves that run down your back, which (trust me) then causes havoc through your nervous system and alarm bells (pain) start to ring.</p>\n<p><strong>What's the solution?</strong></p>\n<p>Right now, I am working on it. If you get yourself in this position, there is no magic pill. The age old  \"Just get some rest\" could well make things worse, but \"just get moving\" can become impossible if the problem leads to great pain and very restricted movement. I had an epidural (or in other words a back injection) of steroids that reduce the pain and irritation in the area, which should in theory leave me more free to perform rehab (which I was already doing pre-flare-up) that has been assigned by my therapist. I am also getting acupuncture done once a week. Realistically, I have been told that unless I build my body to work against the herniation that I have, this problem will repeat over and over and over. The problem is there now and there is little to nothing I can do to fully fix the problem in the mid to long distance future.</p>\n<p><strong>Why is this relevant to you?</strong></p>\n<p>It simply could be that my problem is that I was handed a crappy set of genes. You're probably not wrong. There are a few people in my family that have struggled with this problem over the years. However none of them have had it so severely (up until my grandparents at least). Could this be because of my career? Well, again I can't say for certain. But I suspect it could well be the case. Time and time again over this last month I have been asked what I do for a living. The response of \"software developer\" has most of the time led to an \"ah yes\", followed by a long discussion on how I practice good desk hygiene. Below are two pieces of advice I was given from professionals along the way, and I hope that they peak your interest.</p>\n<p><em><strong>There is no such thing as a perfectly ergonomic position</strong></em></p>\n<p>If you think your Herman Miller chair is your one way ticket to a full day of working in a seat, I would encourage you to think again. It is considered by many that <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4152382/#:~:text=Go%20to%3A-,INTRODUCTION,-Low%20back%20pain\">prolonged sitting of any kind can lead to the same symptoms</a> that I have experienced over the last few weeks. Tim Cook (CEO of Apple) even said that sitting is the \"<a href=\"https://www.phonearena.com/news/Apple-Park-standing-desks_id105769\">new cancer</a>\", and stated that standing desks were purchased for each employee at the apple campus. Could you ignore this advice and be just fine? Sure. But I would implore you to read the previous sections that outline the pain these problems cause before deciding whether this is a risk you want to take.</p>\n<p>We all need to be somewhat stationary to do our jobs (unless there is some ingenious new method I have not heard of), so how else can you work? Standing up? Well yes, but again, staying static, even standing for prolonged periods can bring its own problems, especially if you're slouching around, which I have actually found hard to catch myself doing. The key is movement. I have been told now by a couple of professionals that changing positions frequently (literally as frequently as possible) is the best way to go. Sure, sit for a little bit, but switch things up. Stand for an hour or so, move over to the sofa and put your feet up. Most importantly, \"ding!\". Move away from the computer! The annoying software was there for a reason that I can now understand. Take a work call on your phone and walk in the park, allhands while doing chores around the house. This might infuriate some, but unfortunately I don't see any other way of mitigating the risks I have mentioned above.</p>\n<p><em><strong>Ergonomics aren't completely useless: making sure we are enabled is critical!</strong></em></p>\n<p>Like many companies out there, I work at a fully remote company. There is no office attendance policy, so instead we make our office the home. Therefore, the days of the ergonomic assessor coming round to the desk have gone. The pre-purchased and approved furniture (that was expensive for a reason) is no more, and the process of making the office a safe place (or not doing anything at all) is now in the hands of the employee. The cheaply made desk furniture that can squeeze into the corner of your bedroom has arisen, as well as cheaply made chairs that do nothing to keep one safe. Even worse, some might find their first month at a new job working from a kitchen table in a wooden chair. What is the protocol in place at your company for a new joiner in such a position? Do you have one?</p>\n<p>All of this made me ask the question, \"is having a safe environment to work no longer the employers responsibility?\". I pondered over this, and it somewhat reminded me of the <a href=\"https://www.brownejacobson.com/insights/uber-drivers-entitled-to-workers-rights\">Uber workers rights cases</a> of the past. While I work for my employer, should they not be responsible for at least trying to ensure that I am helping myself? While this may not be law, I think that any business should want what is good for their employees. What exactly does that look like? I'm not so sure.</p>\n<p>I am lucky enough to be at an employer that gives me a hefty office equipment budget, but after shelling out on a 14\" Macbook Pro, I am left with barely a couple of pennies to spare. \"Well maybe you should have thought before buying an outrageously overpriced machine\" I can hear one say. Well yes, lesson learned. However I do think more could be done within every remote business to help employees take care of their health while they are working, particularly in the area of ergonomics. How exactly this is handled should be up to the specific business, but hopefully you will agree that ensuring an employee can keep themselves healthy while working is more important than the speed and power of their laptop.</p>\n<p>Like high visibility jackets and hard hats at a construction site, I believe that employers should have an obligation to ensure that employees are using appropriate equipment before they embark on their working adventure. Like at my first job, the furniture might not be designed by Jony Ive, and it could even be second hand from a previous employer, but it darn should be available to help prevent real problems.</p>\n<p><em><strong>Please. Just don't over work</strong></em></p>\n<p>I might have mentioned that I work at a virtual company. Once upon a time, over working would involve being sat in a deserted and dark office, with the lights occasionally turning on when a cleaner walked past. In the remote world, I can slap on some of my favourite tunes, grab a ready meal from the fridge and keep on cracking! Back into my cosy chair I go and more work to be done.</p>\n<p>This doesn't just ruin your social life. It doesn't just burn you out and add to stress (which can lead to physical problems such as back pain). It means you're spending even more time stuck. Not moving, not walking, stretching, running, bending. You're driving yourself towards a world of problems, and trust me, they really hurt.</p>"
    },
    "_id": "blog/back.md",
    "_raw": {
      "sourceFilePath": "blog/back.md",
      "sourceFileName": "back.md",
      "sourceFileDir": "blog",
      "contentType": "markdown",
      "flattenedPath": "blog/back"
    },
    "type": "Doc"
  },
  {
    "title": "Lets direct Kubernetes traffic with... Contour? 🚦",
    "body": {
      "raw": "A ground-up exploration of containers, Kubernetes and web traffic routing awaits!\n<!--more-->\n\nSo you understand the premise of a container, pretty cool right? You have one way or another been taken through a rundown of how Kubernetes can help harness these nifty little containers, and enable enterprises to run their services with a whole new level of control and efficiency. Now you feel accomplished in your understanding of this new trend, and someone has burst your bubble by uttering a sentence like, \"I use Contour as my ingress controller; it deploys Envoy as the reverse proxy and load balancer, what do you use?\". You sit in your seat paralysed for a brief moment as your short-lived confidence evaporates... and then you bellow... 'What the Heptio?!'.\n\nWell good news, this *premier* blog post is aimed to try and restore your faith in the world of modern applications, and provide an overview of the principles that surround the Contour platform. 👏\n\n#### *Brief Side-note*\n\nIf you don't understand what I mean from the above statement, I guess this is the moment that you navigate to your search bar and get yourself anywhere other than here. Please don't! You are only a couple of lines away from some interesting articles that will free you of those 'What the Hell?' signals your brain is resonating through your soul. Take a look at the provided links to get your head around the container, and how it brought about container orchestrators such as Kubernetes... it's cool, I promise:\n\n[What is Docker? \"In Simple English\"](https://blog.usejournal.com/what-is-docker-in-simple-english-a24e8136b90b)\n\n[What is Kubernetes](https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/)\n\n_(I also thought the below video would be cool to add, as I think it's actually a pretty neat explanation 😂)_\n{{< youtube 4ht22ReBjno >}}\n&nbsp;\n## **First of all... What the Hell?**\nSo you have your Kubernetes cluster. Put simply, a collection of compute nodes (machines) that are held to the mercy of a cluster master, that will carry out the instructions it is given. Using the nodes as its workers, it decides which containerised workloads are going to run on each of the nodes it has in it's control. Bliss. All you needed to do was define to the master what it was you wanted, and it takes care of it for you. You run a ```kubectl get pods``` and sit back in your chair with a smug look on your face, as you gaze at your newly created pods, housing a shiny new web application you're going to deploy. And then you think \"but how does Kubernetes know how to direct traffic intended for the web application to these pods?\". Well... it doesn't, at least not yet. This is where Ingress comes in.\n\nIn the Kubernetes world, Ingress is an application layer level (OSI Layer 7), policy defined method of directing external users to services running on a Kubernetes cluster. As forementioned, if you have a bunch of web services running inside pods, you need to make them available from a public IP address or domain (e.g. https://blog.chaosinthe.dev). Kubernetes Ingress features two main components; an ingress controller and ingress resources.\n\nAs seen in the diagram below, an ingress controller is a service based on a reverse proxy / load balancer ([handy definition if needed](https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/)) which once configured routes incoming traffic to the correct application within your cluster. This ingress controller can be chosen by the cluster admin, and there are a few to choose from (e.g. Nginx, Traefik, Contour 😲). The configuration of said controllers is handled by the cluster master, directed by the cluster resources; a collection of rules and configurations provided by yours truly (e.g. YAML file).\n\n{{< figure src=\"/img/post-1/ingress1.png\">}}\n\nOk awesome, you're now entitled to lean back in your chair again, with the satisfaction that your web application is now accessible to whomever you wish it to be, through a domain name that leads back to your k8s cluster, and any requests get handled by the ingress controller, defined by your delicately defined ingress resources YAML.\n\n## ⌇🔵 Spicing Things up with Contour 🔵⌇\n\nOk, so from the casual name drop in the previous section, we can deduce that Contour is an Ingress controller for Kubernetes. But what would makes it a good choice for Kubernetes users or enterprise environments? The Contour controller supports dynamic configuration updates. Many freely available ingress controllers designed for use in Kubernetes can be configured to work well. However, performance is hindered by the fact that any changes to the configuration files (Ingress Resources) require a restart to the service before said changes come into effect. In enterprise environments, this can very easily be seen as suboptimal for reliability and performance, not to mention just a bit of a pain. With Contour, you can kiss goodbye to these problems, with dynamic changes enabled through the use of a cool little proxy called Envoy, no restart required 🥳.\n\nWhat else? Contour also features multi-team ingress delegation to protect service access on multi-team clusters 😄... ok ok, I can feel the bubble bursting a little also. To summarise in short, Kubernetes uses a control mechanism called Role Based Access Control (RBAC), that allows the cluster admins to restrict access of development teams interacting with their infrastructure to exclusively the namespaces relevant to their work. This stops the age old problem of a rogue engineering employee deciding to get their own back on a fellow employee that argued with them in the cafeteria, changing all their production front ends to cat memes.\n\nRBAC is a superb way to manage access to clusters, however issues can arise with regard to multi-team clusters configuring ingress. Ingress is a 'namespaced' resource, and so control of it can be managed in the same segmented nature, but collisions can occur from the way it is configured by different teams. [Alexander Brand's](https://blog.heptio.com/improving-the-multi-team-kubernetes-ingress-experience-with-heptio-contour-0-6-55ae0c0cadef) blog post on this subject eloquently describes the scenario where two teams point the same domain extension (e.g. www.example.org/blog) to different service endpoints. In this instance, nothing has been defined to tell the controller what to do in the event of such a conflict, and 'team two' who created the conflict, are unaware of the problem they are creating... *scary* 👻. Contour brings a solution to this nightmare with the IngressRoute custom resource definition (CRD). A CRD is a clever feature, as it allows users to add their own custom built objects to tailor the capabilities of Kubernetes to their liking ([more info here](https://medium.com/velotio-perspectives/extending-kubernetes-apis-with-custom-resource-definitions-crds-139c99ed3477)). Put simply, the IngressRoute feature brought to Kubernetes by Contour gives cluster admins full control of which teams are permitted to use which domain extensions in their resource definitions. So in the case of our engineering team who tried to steal the '/blog' domain extension; they have their configuration ignored by contour and are informed of the mistake they have made. Once again if you fancy a more detailed explanation that is still succinct, please go to Alex's article (linked above).\n\n\n## Okay... so what's Envoy?\n{{< figure src=\"/img/post-1/envoy.png\">}}\nI'm sure by now you have done a quick google search to find out what [Envoy](https://www.envoyproxy.io/) is. You've found the cool looking pink logo, its beginnings as a project inside Lyft, and the ties that it has with Googles Istio project. But you may still be scratching your head and thinking like I did, \"what makes it so special?\".\n\nWell yes, it's a proxy.. just the kind that you'd find inside one of your ingress controllers. But there are some key factors that made it a great choice when the Contour project was being created. First of all, Envoy is officially supported by the Cloud Native Computing Foundation ([CNCF](https://www.cncf.io/cncf-envoy-project-journey/#)). This ensures there will be long term support and exposure for the project, making it advantageous for deployment in enterprise environments. However, in terms of its architecture, what makes it so appealing is that this proxy is 'API driven'. What does this mean? Well in the instance of the proxies mentioned earlier such as Nginx, a config file must be edited, saved and a service reloaded, before changes are to come into effect. However through Envoys APIs ([What is an API?](https://www.youtube.com/watch?v=s7wmiS2mSXY)), any changes that are needed to be made to its configuration, can be done without restart or disturbance. Yes, you guessed it, this is how the Contour project manages to give dynamic configuration updates with such ease. Finally, it is written in C++, which gives it the ability to execute very quickly, and run very efficiently. Why? Well maybe it is a bit out of scope for this post, maybe another time 😊.\n\nIf you want a more detailed/full description of the envoy proxy, and why it was a great design choice for the Contour project; please see the TGIK episode by Joe Beda that I have embedded below, and go to ```playtime 13:00``` (watch the whole episode if you have the interest and the time to kill).\n\n{{< youtube -Hvfl6zOLGE >}}\n\n## Tell me more 🙏\nOkay! So first of all congratulations for getting this far, and have somehow managed to not cringe too hard at my cheesy journalism. I hope by now that you feel versed enough in the world of project contour to follow any deeper documentation. If so, crack on! Personally, I think the TGIK episode below is a great place to start, and from there you can look over the documentation to your hearts content. I have provided the relevant pages for both Contour and Envoy below.\n\n[Contour Project](https://projectcontour.io/)\n\n[Contour Project Github](https://github.com/projectcontour/contour)\n\n[Envoy Project](https://www.envoyproxy.io/)\n\n[Envoy Project Github](https://github.com/envoyproxy/envoy)\n\nI hope that this article has been worth the 10-15 minutes, and you feel that those 'what the Hell?' feelings have faded away into nothingness. At the very least, I hope that you have learned something interesting about the world of cloud native, and if there is anything I can do to help, or any feedback you would like to give; please reach out to me 🙋🏻‍♂️.\n\nOn the subject of feedback, any feedback is greatly received. I am still learning, so if anyone finds a small hole/caveat in my overview, that's ok! I would really like to know, so I can review and make the necessary changes. I have even got a comments section below (so exciting), so feel free to discuss what you like down there.\n",
      "html": "<p>A ground-up exploration of containers, Kubernetes and web traffic routing awaits!</p>\n<p>So you understand the premise of a container, pretty cool right? You have one way or another been taken through a rundown of how Kubernetes can help harness these nifty little containers, and enable enterprises to run their services with a whole new level of control and efficiency. Now you feel accomplished in your understanding of this new trend, and someone has burst your bubble by uttering a sentence like, \"I use Contour as my ingress controller; it deploys Envoy as the reverse proxy and load balancer, what do you use?\". You sit in your seat paralysed for a brief moment as your short-lived confidence evaporates... and then you bellow... 'What the Heptio?!'.</p>\n<p>Well good news, this <em>premier</em> blog post is aimed to try and restore your faith in the world of modern applications, and provide an overview of the principles that surround the Contour platform. 👏</p>\n<h4><em>Brief Side-note</em></h4>\n<p>If you don't understand what I mean from the above statement, I guess this is the moment that you navigate to your search bar and get yourself anywhere other than here. Please don't! You are only a couple of lines away from some interesting articles that will free you of those 'What the Hell?' signals your brain is resonating through your soul. Take a look at the provided links to get your head around the container, and how it brought about container orchestrators such as Kubernetes... it's cool, I promise:</p>\n<p><a href=\"https://blog.usejournal.com/what-is-docker-in-simple-english-a24e8136b90b\">What is Docker? \"In Simple English\"</a></p>\n<p><a href=\"https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/\">What is Kubernetes</a></p>\n<p><em>(I also thought the below video would be cool to add, as I think it's actually a pretty neat explanation 😂)</em>\n{{&#x3C; youtube 4ht22ReBjno >}}\n </p>\n<h2><strong>First of all... What the Hell?</strong></h2>\n<p>So you have your Kubernetes cluster. Put simply, a collection of compute nodes (machines) that are held to the mercy of a cluster master, that will carry out the instructions it is given. Using the nodes as its workers, it decides which containerised workloads are going to run on each of the nodes it has in it's control. Bliss. All you needed to do was define to the master what it was you wanted, and it takes care of it for you. You run a <code>kubectl get pods</code> and sit back in your chair with a smug look on your face, as you gaze at your newly created pods, housing a shiny new web application you're going to deploy. And then you think \"but how does Kubernetes know how to direct traffic intended for the web application to these pods?\". Well... it doesn't, at least not yet. This is where Ingress comes in.</p>\n<p>In the Kubernetes world, Ingress is an application layer level (OSI Layer 7), policy defined method of directing external users to services running on a Kubernetes cluster. As forementioned, if you have a bunch of web services running inside pods, you need to make them available from a public IP address or domain (e.g. https://blog.chaosinthe.dev). Kubernetes Ingress features two main components; an ingress controller and ingress resources.</p>\n<p>As seen in the diagram below, an ingress controller is a service based on a reverse proxy / load balancer (<a href=\"https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/\">handy definition if needed</a>) which once configured routes incoming traffic to the correct application within your cluster. This ingress controller can be chosen by the cluster admin, and there are a few to choose from (e.g. Nginx, Traefik, Contour 😲). The configuration of said controllers is handled by the cluster master, directed by the cluster resources; a collection of rules and configurations provided by yours truly (e.g. YAML file).</p>\n<p>{{&#x3C; figure src=\"/img/post-1/ingress1.png\">}}</p>\n<p>Ok awesome, you're now entitled to lean back in your chair again, with the satisfaction that your web application is now accessible to whomever you wish it to be, through a domain name that leads back to your k8s cluster, and any requests get handled by the ingress controller, defined by your delicately defined ingress resources YAML.</p>\n<h2>⌇🔵 Spicing Things up with Contour 🔵⌇</h2>\n<p>Ok, so from the casual name drop in the previous section, we can deduce that Contour is an Ingress controller for Kubernetes. But what would makes it a good choice for Kubernetes users or enterprise environments? The Contour controller supports dynamic configuration updates. Many freely available ingress controllers designed for use in Kubernetes can be configured to work well. However, performance is hindered by the fact that any changes to the configuration files (Ingress Resources) require a restart to the service before said changes come into effect. In enterprise environments, this can very easily be seen as suboptimal for reliability and performance, not to mention just a bit of a pain. With Contour, you can kiss goodbye to these problems, with dynamic changes enabled through the use of a cool little proxy called Envoy, no restart required 🥳.</p>\n<p>What else? Contour also features multi-team ingress delegation to protect service access on multi-team clusters 😄... ok ok, I can feel the bubble bursting a little also. To summarise in short, Kubernetes uses a control mechanism called Role Based Access Control (RBAC), that allows the cluster admins to restrict access of development teams interacting with their infrastructure to exclusively the namespaces relevant to their work. This stops the age old problem of a rogue engineering employee deciding to get their own back on a fellow employee that argued with them in the cafeteria, changing all their production front ends to cat memes.</p>\n<p>RBAC is a superb way to manage access to clusters, however issues can arise with regard to multi-team clusters configuring ingress. Ingress is a 'namespaced' resource, and so control of it can be managed in the same segmented nature, but collisions can occur from the way it is configured by different teams. <a href=\"https://blog.heptio.com/improving-the-multi-team-kubernetes-ingress-experience-with-heptio-contour-0-6-55ae0c0cadef\">Alexander Brand's</a> blog post on this subject eloquently describes the scenario where two teams point the same domain extension (e.g. www.example.org/blog) to different service endpoints. In this instance, nothing has been defined to tell the controller what to do in the event of such a conflict, and 'team two' who created the conflict, are unaware of the problem they are creating... <em>scary</em> 👻. Contour brings a solution to this nightmare with the IngressRoute custom resource definition (CRD). A CRD is a clever feature, as it allows users to add their own custom built objects to tailor the capabilities of Kubernetes to their liking (<a href=\"https://medium.com/velotio-perspectives/extending-kubernetes-apis-with-custom-resource-definitions-crds-139c99ed3477\">more info here</a>). Put simply, the IngressRoute feature brought to Kubernetes by Contour gives cluster admins full control of which teams are permitted to use which domain extensions in their resource definitions. So in the case of our engineering team who tried to steal the '/blog' domain extension; they have their configuration ignored by contour and are informed of the mistake they have made. Once again if you fancy a more detailed explanation that is still succinct, please go to Alex's article (linked above).</p>\n<h2>Okay... so what's Envoy?</h2>\n<p>{{&#x3C; figure src=\"/img/post-1/envoy.png\">}}\nI'm sure by now you have done a quick google search to find out what <a href=\"https://www.envoyproxy.io/\">Envoy</a> is. You've found the cool looking pink logo, its beginnings as a project inside Lyft, and the ties that it has with Googles Istio project. But you may still be scratching your head and thinking like I did, \"what makes it so special?\".</p>\n<p>Well yes, it's a proxy.. just the kind that you'd find inside one of your ingress controllers. But there are some key factors that made it a great choice when the Contour project was being created. First of all, Envoy is officially supported by the Cloud Native Computing Foundation (<a href=\"https://www.cncf.io/cncf-envoy-project-journey/#\">CNCF</a>). This ensures there will be long term support and exposure for the project, making it advantageous for deployment in enterprise environments. However, in terms of its architecture, what makes it so appealing is that this proxy is 'API driven'. What does this mean? Well in the instance of the proxies mentioned earlier such as Nginx, a config file must be edited, saved and a service reloaded, before changes are to come into effect. However through Envoys APIs (<a href=\"https://www.youtube.com/watch?v=s7wmiS2mSXY\">What is an API?</a>), any changes that are needed to be made to its configuration, can be done without restart or disturbance. Yes, you guessed it, this is how the Contour project manages to give dynamic configuration updates with such ease. Finally, it is written in C++, which gives it the ability to execute very quickly, and run very efficiently. Why? Well maybe it is a bit out of scope for this post, maybe another time 😊.</p>\n<p>If you want a more detailed/full description of the envoy proxy, and why it was a great design choice for the Contour project; please see the TGIK episode by Joe Beda that I have embedded below, and go to <code>playtime 13:00</code> (watch the whole episode if you have the interest and the time to kill).</p>\n<p>{{&#x3C; youtube -Hvfl6zOLGE >}}</p>\n<h2>Tell me more 🙏</h2>\n<p>Okay! So first of all congratulations for getting this far, and have somehow managed to not cringe too hard at my cheesy journalism. I hope by now that you feel versed enough in the world of project contour to follow any deeper documentation. If so, crack on! Personally, I think the TGIK episode below is a great place to start, and from there you can look over the documentation to your hearts content. I have provided the relevant pages for both Contour and Envoy below.</p>\n<p><a href=\"https://projectcontour.io/\">Contour Project</a></p>\n<p><a href=\"https://github.com/projectcontour/contour\">Contour Project Github</a></p>\n<p><a href=\"https://www.envoyproxy.io/\">Envoy Project</a></p>\n<p><a href=\"https://github.com/envoyproxy/envoy\">Envoy Project Github</a></p>\n<p>I hope that this article has been worth the 10-15 minutes, and you feel that those 'what the Hell?' feelings have faded away into nothingness. At the very least, I hope that you have learned something interesting about the world of cloud native, and if there is anything I can do to help, or any feedback you would like to give; please reach out to me 🙋🏻‍♂️.</p>\n<p>On the subject of feedback, any feedback is greatly received. I am still learning, so if anyone finds a small hole/caveat in my overview, that's ok! I would really like to know, so I can review and make the necessary changes. I have even got a comments section below (so exciting), so feel free to discuss what you like down there.</p>"
    },
    "_id": "blog/first-posts.md",
    "_raw": {
      "sourceFilePath": "blog/first-posts.md",
      "sourceFileName": "first-posts.md",
      "sourceFileDir": "blog",
      "contentType": "markdown",
      "flattenedPath": "blog/first-posts"
    },
    "type": "Doc"
  },
  {
    "title": "WTH Post 0: Peeking Behind the Curtains 🕵🏻‍♂️",
    "body": {
      "raw": "\nSo unlike the majority of posts that I will hopefully put on here, this one will be a little more 'build log' orientated. That's not to mean that by the end of reading you won't have learned anything new. hopefully you will find it inciteful, and maybe even helpful for your own learning and exploration into the field of cloud native platforms. Believe me; The articles that sit on this blog are only where the work really begins. This is just as much the case for any public facing website or application that runs in the industry today. I think it's all very exciting, and hopefully by the end of this article you will agree (at least partially).\n\nOver the next ten or so minutes, I am going to take you on a journey of how this blog was born, and how it leverages the best of open-source and cloud native platforms to give it (I hope), a reliable and continuously developing design that all of you readers sitting at the other end can benefit from. I know what you are thinking; \"What the Hell? Why would you use enterprise grade platforms, designed for large scale deployments, just to host your casual little web page?\". Well it wouldn't really be a WTH blog post without having to stop and scratch your head at least once now would it? So, without further ado...\n\n## A Blog Site?\n\nIf you're still wandering, no I am unfortunately not a professionally trained technology journalist for Wired or ArsTechnica. I am a young engineer, fresh out of University with a degree in Electronic and Computer Engineering. Over the past 10 years of my life, I have embarked on my own technological journey that has spanned from basic low level chip design (don't ask me about VHDL, I don't remember much), all the way up to configuring and debugging pre-release data-centre hardware at team blue. No [spectre/meltdown](https://meltdownattack.com/) wasn't my fault, although it I definitely did choose an exciting time to be at the company.\n\nI am now at the stage in my life where choosing the next step is both an exciting, yet cumbersome decision. But I have been fortunate enough to have taken a shining to the area of enterprise open-source software, which is what has led me here. As I am sure you will also understand, getting started with these platforms can be difficult. These platforms and tools are designed to be deployed on datacentre level hardware, at an industrial scale that few regular people will ever see, by large companies with a list of applications to run so long that it looks more like a £100 supermarket receipt. And so, this blog site seemed to be a no brainer; giving a means of noting down any learning performed over the next few months, with the added benefit of dragging along other casually interested folks on this journey with me!\n\n## Step 1. Architecting the site... from the ground to the 'cloud' 🌩\n\nIf any website or application is to be accessible over the internet, of course it must be hosted on a computer with a network connection somewhere in the world. While my own experience providing such services hasn't been extensive, I had prior experience with services such as system/application monitors ([NetData](https://github.com/netdata/netdata)), application remotes, automation services and private cloud instances ([NextCloud](https://github.com/nextcloud/server)). These services all trundled along happily for a couple years, until the power supply on my home server decided to give up (RIP 💀), and I was left with nothing. Or so I thought...\n\nI was pointed towards the [Google Cloud Platform](https://cloud.google.com/gcp), which offers $300 in free credit to new users signing up. While that might not cut it for some of the big companies, as an individual just looking to learn, this is a gift. And so, when deciding to embark on this journey, Google Cloud seemed like the obvious place. Plans to build a M.O.A.W (mother of all workstations), weren't going to materialise instantly, but by the time I was to run out of credit, I would hopefully be there with them.\n\n### Kuh-Kuh-Kuh-Kubernetes? Sorry I'm allergic to buzzwords.\n\nAs the deployment of this blog site was not just about what was on it, but also making the deployment experience sufficiently challenging and useful in my cloud native voyage, the obvious choice for a platform to use was Kubernetes. The technology is so hot right now that I almost feel bad for saying the word. However, after spending the last few months researching it, it seems obvious that it holds an incredible amount of power (hype jokes aside), while also offering well to me due to it being situated within the Linux world. The best part for me is that it is open-source, featuring many different weird and wonderful ways to deploy it (Kind, Minikube and Kubeadm just to name a few). Therefore, combined with Google's very generous helping of $300 to spend in their Cloud Platform candy store, Google Kubernetes Engine was my poison of choice. \n\n\n![gke interface](/img/post-0/gkeInterface.png \"The web interface provided for GKE\")\n\nThis is simply a cluster of VM instances with specifications that can be chosen by the user. I was going to tell you that each node was running a [Debian](https://www.debian.org/releases/wheezy/amd64/ch01s03.html.en) based version of Linux, but lo and behold it's Chrome OS 😲... at least they found a good use for it somehow! GKE makes the setup of a k8s cluster super easy, as you define it's specifications and from their you're faced with easy to use tools that allow you to interface with it and start configuring.\n\n### Hugo... the Web Framework, not the Super Villian 🦹🏼‍♂️\n\n{{< figure src=\"/img/post-0/Hugo.png\">}}\n\nAfter choosing to follow down the route of GKE, I started following tutorials for running WordPress on GKE. Was there much thought put into this? Definitely not, but thankfully I was suggested by a friend to take a look at a static site framework called [Hugo](https://gohugo.io/). This is a neat little tool written in Golang (hence the name), that takes content such as markdown text files, images, community made [theme templates](https://themes.gohugo.io/) and config files, generating a full static site written in HTML and CSS. This means that I can concentrate a little more on the look, feel and content, while also getting to have a good level of customisation. This was a great choice, and I'm so far very happy with it. After a bit of reading to understand the directory structure required for the Hugo compiler to build my static site correctly, along with a fair few hours playing with some different theme templates and configs, the site was ready to go!\n\n## Step 2. Deployment\n\n### Giving Hugo a Home 🏠📦\n\nSo, as I just mentioned, the static site I was to find myself with would be made up of raw HTML and CSS files. So, if this was to be the case, I had to figure out a way I could bundle this all up into a workload that could act as an application on my freshly squeezed GKE cluster. There were two considerations to take here. First was that I would need some sort of [web-server](https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_is_a_web_server) application, and second was the fact that it must be able to 'speak Kubernetes'. By this I mean that it must be containerised in some way, so that Kubernetes can throw it into a pod when I create my deployment. \n\n\nAfter jogging my memory and doing a little research, I decided on taking an Nginx docker image as a template and injecting my Hugo page into it. In order to make this magic happen, I used the docker command line interface's 'build' command, along with a dockerfile (seen above). My blog now has a comfy little box to live in (a docker image) that I can throw on whichever platform I like, and it will always (more or less) run as expected. This is great for testing locally before deploying it into the big bad world 🌎.\n\n\n![docker build](/img/post-0/dockerBuild.png \"'cat' command, showing the contents of the Dockerfile, 'docker build' command to build from the Dockerfile specs and 'docker images' to show the information regarding the compiled image\")\n\n### Life is a journey... even for a container 🚀\n\nSo now I have a working image, crammed full of content intended for the lovely citizens of the internet to consume at their own free will; surely it is just a matter of uploading it to the GKE cluster and job done, right? Don't worry, the fun isn't over yet. In the image that was built above, it only contains the HTML and CSS of the site at that moment in time. When I deploy it on my cluster, sure it will work, but if I want to update the site, I'll have to do the process all over again. That means another hugo build command, one more docker build, yet more pushing to some repository of images that my GKE cluster can access, then finally telling the cluster to kill all the pods in my deployment in order to create new ones with the latest image. Of course, I could have just made a little bash script to automate this process locally... but that felt like a shortcut in this case. I sought a method to approach this in a way that would teach me something new; the aim of the game for this project.\n\nIn an ideal world, adding to the blog would be as simple as opening any machine that I can run hugo and access a repository of the sites project files. then I could pull down the files, make the relevant changes, produce the HTML/CSS outputs; before pushing it all back again. Then as if by magic, some process spots the change to the repo, triggering a docker build on some VM instance, before finally yelling at Kubernetes 'Yo, I've got a newer image for you'. What I have just described is known in the enterprise as a CI:CD Pipeline. CI, 'Continuous Integration'; is an easy method of changing, testing and sharing code (use of code repository and Hugo). CD, 'Continuous Delivery'; refers to the automation of building an application, as well as it's deployment into the production environment (said vudu magic that spots the code change and triggers a build, before GKE creates fresh pods with the new container release inside).\n\n<figure>\n<img src=\"/img/post-0/dockerAutomated.png\" />\n<figcaption>\n<h4>Overview of Docker automated builds functionality on Docker Hub web UI</h4>\n</figcaption>\n</figure>\n\n\n![Docker Automated Builds](/img/post-0/dockerAutomated.png \"Overview of Docker automated builds functionality on Docker Hub web UI\")\n\nTo achieve this, the obvious first choice for enabling easy integration was [Github](https://www.howtogeek.com/180167/htg-explains-what-is-github-and-what-do-geeks-use-it-for/). It's free, and I was also comfortable using it. That way I could have a saved snapchat of each update to my site, with easy access to it from just about every electronic device I could think to work on. The CD side is where things got interesting for me, as I needed to figure out how I could easily trigger a docker build from a git commit, saving myself a step. Docker came to the rescue here, with the ['automated build'](https://docs.docker.com/docker-hub/builds/) feature within docker hub. Using a webhook, a push to my github repository initiates a new build on a Docker hosted VM, and then places it in a docker hub repository that you can easily reference within your Kubernetes deployment. As for triggering new pods to be created within GKE? This will hopefully come in the near future 🤞. I have been looking at an awesome tool called [Flux](https://github.com/fluxcd/flux), that provides this kind of functionality. This is something I will hopefully look into soon, but I realised that maybe creating a 'dev' branch to commit to before merging it into the master release would be preferable. This way I won't accidentally publish half my article midsession 😂.\n\n{{< figure src=\"/img/post-0/flux.png\">}}\n\n### Back to GKE: Deployments, Ingress and... TLS (Torturously Long Setback 😭)\n\nBefore I crack away with an overview of how I went about working on this part of the project; just a short disclaimer. Due to the number of headaches, misconceptions and design changes that led to this most current configuration, I will keep things brief; **no braincell's shall be damaged in the making of this post.**\n\n#### Deployment\nFrom the point of view of deployment, this was a pretty simple step after the months of reading I had done about k8s and kubectl. A deployment YAML config file was created to ensure that if needed, I could redeploy the same configuration elsewhere, and minimal configuration would be required. In fact, I actually deleted and recreated my GKE cluster a couple of times during setup (unfortunately I noobed out a few times), and this saved my bacon. I have added my deployment below, and I have added features to it such as [rolling updates](https://kubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/) and [grace periods](https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-terminating-with-grace) (super super neat!). After having my pods running safely on GKE I thought 'great, this is easy!'. Fortunately... the next stage blew my mind a little.\n\n<figure>\n<img src=\"/img/post-0/yamls.png\" />\n<figcaption>\n<h4>Yaml files used for deployment and Ingress</h4>\n</figcaption>\n</figure>\n\n![Docker Automated Builds](/img/post-0/yamls.png \"Yaml files used for deployment and Ingress\")\n\n#### DNS\nGoogle Cloud DNS provided a reliable method of redirecting the user entering the domain name of the site to the appropriate Ingress IP. Ahh wonderful, Ingress. If you've been keeping an eye on the blog, the first post was all about Ingress, so I should be a master at this step. \"It's gonna be a piece of cake\", I thought. No. No it wasn't.\n\n#### Ingress\n*Brief Note: While I am sure that all of those reading this will have heard of HTTP/HTTPS, you may be unsure as to what the actual difference is between them. If so read [this 😊](https://www.geeksforgeeks.org/difference-between-http-and-https/)*\n\nFrom the perspective of configuring ingress from the domain to the desired endpoint using http (non-encrypted), all went as expected. I followed the [documentation](https://cloud.google.com/kubernetes-engine/docs/tutorials/http-balancer) provided by Google, and it all went according to plan. The same cannot be said while configuring SSL/TLS. Google cloud provides the capability to automatically have your certificates managed by google... fantastic! Although, as much as I want to tell you that this whole process went smoothly... it really didn't. Granted, this may be due to my lack of maturity as a Kubernetes admin, but the problem boiled down to the fact that no matter how hard I tried.. I just couldn't seem to get requests to default or redirect to port 443 (HTTPS). I tried endless tricks, workarounds, guides, forum post answers... but none brought me to the desired result of secure access 😑.\n\n\n{{< figure src=\"/img/post-0/LostInWoods2.gif\">}}\n\nThe problem seemed a little to do with limitations in the GKE ingress controller, and maybe I was looking in the wrong place, but documentation was both vague and lacking. Furthermore, let's just say I was not the only one that had issues in this area. So I figured, scrap it. Let's deploy an ingress controller that is fully managed inside of my Kubernetes cluster. 'Aha!' I thought, 'let's use Contour!'. After all I just spent time overviewing it (quick promo for previous [post](https://blog.chaosinthe.dev/posts/first-posts/)), so it would be fitting that it was to actually be used for the ingress of this site!\n\nFollowing Dave Cheney's [guide](https://projectcontour.io/guides/cert-manager/), that provides a step by step walkthrough for deploying Contour; I was up and running within an hour. Compared to the two days of stumbling around aimlessly (reference to Jim Carey above), this efficiency was welcoming. Also included within the guide (and what I was most excited about) is the steps for deploying cert-manager; a k8s addon for automating the management and issuance of TLS certificates... 'ooh la la' I thought. And 'Ooh la la' I uttered not long later. After deploying Contour and cert-manager, declaring their use through the ingress annotations and pairing the relevant secrets (containing my certificates) was all it took for fully working Ingress with added TLS that was fully enforced by the ingress controller 🍾.\n\n## Step 3. Step back and Relax\nSo that's it. That is how I went about configuring and deploying the webpage that sits before your very eyes. While this article provides an overview, there were many more headaches, problems, breakdowns and confusions that took place in the process. But overall, I am happy with how it has all turned out. The plan in the coming weeks and months is to flesh it out further, with more articles (of course weekly, I've promised myself), and some added functionality (shiny web UI features 😲).\n\nIf you have felt anything at all about this article, please provide me with some feedback, and I can take it in my stride moving forward with the project. If you have learned something I would also love to hear as that is what this blog is all about! Finally, if you have any ideas about platforms or tools that I could overview, do not hesitate to forward me a suggestion, and I will do my best to provide something informative yet exciting.\n\n\n\n\n\n\n",
      "html": "<p>So unlike the majority of posts that I will hopefully put on here, this one will be a little more 'build log' orientated. That's not to mean that by the end of reading you won't have learned anything new. hopefully you will find it inciteful, and maybe even helpful for your own learning and exploration into the field of cloud native platforms. Believe me; The articles that sit on this blog are only where the work really begins. This is just as much the case for any public facing website or application that runs in the industry today. I think it's all very exciting, and hopefully by the end of this article you will agree (at least partially).</p>\n<p>Over the next ten or so minutes, I am going to take you on a journey of how this blog was born, and how it leverages the best of open-source and cloud native platforms to give it (I hope), a reliable and continuously developing design that all of you readers sitting at the other end can benefit from. I know what you are thinking; \"What the Hell? Why would you use enterprise grade platforms, designed for large scale deployments, just to host your casual little web page?\". Well it wouldn't really be a WTH blog post without having to stop and scratch your head at least once now would it? So, without further ado...</p>\n<h2>A Blog Site?</h2>\n<p>If you're still wandering, no I am unfortunately not a professionally trained technology journalist for Wired or ArsTechnica. I am a young engineer, fresh out of University with a degree in Electronic and Computer Engineering. Over the past 10 years of my life, I have embarked on my own technological journey that has spanned from basic low level chip design (don't ask me about VHDL, I don't remember much), all the way up to configuring and debugging pre-release data-centre hardware at team blue. No <a href=\"https://meltdownattack.com/\">spectre/meltdown</a> wasn't my fault, although it I definitely did choose an exciting time to be at the company.</p>\n<p>I am now at the stage in my life where choosing the next step is both an exciting, yet cumbersome decision. But I have been fortunate enough to have taken a shining to the area of enterprise open-source software, which is what has led me here. As I am sure you will also understand, getting started with these platforms can be difficult. These platforms and tools are designed to be deployed on datacentre level hardware, at an industrial scale that few regular people will ever see, by large companies with a list of applications to run so long that it looks more like a £100 supermarket receipt. And so, this blog site seemed to be a no brainer; giving a means of noting down any learning performed over the next few months, with the added benefit of dragging along other casually interested folks on this journey with me!</p>\n<h2>Step 1. Architecting the site... from the ground to the 'cloud' 🌩</h2>\n<p>If any website or application is to be accessible over the internet, of course it must be hosted on a computer with a network connection somewhere in the world. While my own experience providing such services hasn't been extensive, I had prior experience with services such as system/application monitors (<a href=\"https://github.com/netdata/netdata\">NetData</a>), application remotes, automation services and private cloud instances (<a href=\"https://github.com/nextcloud/server\">NextCloud</a>). These services all trundled along happily for a couple years, until the power supply on my home server decided to give up (RIP 💀), and I was left with nothing. Or so I thought...</p>\n<p>I was pointed towards the <a href=\"https://cloud.google.com/gcp\">Google Cloud Platform</a>, which offers $300 in free credit to new users signing up. While that might not cut it for some of the big companies, as an individual just looking to learn, this is a gift. And so, when deciding to embark on this journey, Google Cloud seemed like the obvious place. Plans to build a M.O.A.W (mother of all workstations), weren't going to materialise instantly, but by the time I was to run out of credit, I would hopefully be there with them.</p>\n<h3>Kuh-Kuh-Kuh-Kubernetes? Sorry I'm allergic to buzzwords.</h3>\n<p>As the deployment of this blog site was not just about what was on it, but also making the deployment experience sufficiently challenging and useful in my cloud native voyage, the obvious choice for a platform to use was Kubernetes. The technology is so hot right now that I almost feel bad for saying the word. However, after spending the last few months researching it, it seems obvious that it holds an incredible amount of power (hype jokes aside), while also offering well to me due to it being situated within the Linux world. The best part for me is that it is open-source, featuring many different weird and wonderful ways to deploy it (Kind, Minikube and Kubeadm just to name a few). Therefore, combined with Google's very generous helping of $300 to spend in their Cloud Platform candy store, Google Kubernetes Engine was my poison of choice.</p>\n<p><img src=\"/img/post-0/gkeInterface.png\" alt=\"gke interface\" title=\"The web interface provided for GKE\"></p>\n<p>This is simply a cluster of VM instances with specifications that can be chosen by the user. I was going to tell you that each node was running a <a href=\"https://www.debian.org/releases/wheezy/amd64/ch01s03.html.en\">Debian</a> based version of Linux, but lo and behold it's Chrome OS 😲... at least they found a good use for it somehow! GKE makes the setup of a k8s cluster super easy, as you define it's specifications and from their you're faced with easy to use tools that allow you to interface with it and start configuring.</p>\n<h3>Hugo... the Web Framework, not the Super Villian 🦹🏼‍♂️</h3>\n<p>{{&#x3C; figure src=\"/img/post-0/Hugo.png\">}}</p>\n<p>After choosing to follow down the route of GKE, I started following tutorials for running WordPress on GKE. Was there much thought put into this? Definitely not, but thankfully I was suggested by a friend to take a look at a static site framework called <a href=\"https://gohugo.io/\">Hugo</a>. This is a neat little tool written in Golang (hence the name), that takes content such as markdown text files, images, community made <a href=\"https://themes.gohugo.io/\">theme templates</a> and config files, generating a full static site written in HTML and CSS. This means that I can concentrate a little more on the look, feel and content, while also getting to have a good level of customisation. This was a great choice, and I'm so far very happy with it. After a bit of reading to understand the directory structure required for the Hugo compiler to build my static site correctly, along with a fair few hours playing with some different theme templates and configs, the site was ready to go!</p>\n<h2>Step 2. Deployment</h2>\n<h3>Giving Hugo a Home 🏠📦</h3>\n<p>So, as I just mentioned, the static site I was to find myself with would be made up of raw HTML and CSS files. So, if this was to be the case, I had to figure out a way I could bundle this all up into a workload that could act as an application on my freshly squeezed GKE cluster. There were two considerations to take here. First was that I would need some sort of <a href=\"https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_is_a_web_server\">web-server</a> application, and second was the fact that it must be able to 'speak Kubernetes'. By this I mean that it must be containerised in some way, so that Kubernetes can throw it into a pod when I create my deployment.</p>\n<p>After jogging my memory and doing a little research, I decided on taking an Nginx docker image as a template and injecting my Hugo page into it. In order to make this magic happen, I used the docker command line interface's 'build' command, along with a dockerfile (seen above). My blog now has a comfy little box to live in (a docker image) that I can throw on whichever platform I like, and it will always (more or less) run as expected. This is great for testing locally before deploying it into the big bad world 🌎.</p>\n<p><img src=\"/img/post-0/dockerBuild.png\" alt=\"docker build\" title=\"&#x27;cat&#x27; command, showing the contents of the Dockerfile, &#x27;docker build&#x27; command to build from the Dockerfile specs and &#x27;docker images&#x27; to show the information regarding the compiled image\"></p>\n<h3>Life is a journey... even for a container 🚀</h3>\n<p>So now I have a working image, crammed full of content intended for the lovely citizens of the internet to consume at their own free will; surely it is just a matter of uploading it to the GKE cluster and job done, right? Don't worry, the fun isn't over yet. In the image that was built above, it only contains the HTML and CSS of the site at that moment in time. When I deploy it on my cluster, sure it will work, but if I want to update the site, I'll have to do the process all over again. That means another hugo build command, one more docker build, yet more pushing to some repository of images that my GKE cluster can access, then finally telling the cluster to kill all the pods in my deployment in order to create new ones with the latest image. Of course, I could have just made a little bash script to automate this process locally... but that felt like a shortcut in this case. I sought a method to approach this in a way that would teach me something new; the aim of the game for this project.</p>\n<p>In an ideal world, adding to the blog would be as simple as opening any machine that I can run hugo and access a repository of the sites project files. then I could pull down the files, make the relevant changes, produce the HTML/CSS outputs; before pushing it all back again. Then as if by magic, some process spots the change to the repo, triggering a docker build on some VM instance, before finally yelling at Kubernetes 'Yo, I've got a newer image for you'. What I have just described is known in the enterprise as a CI:CD Pipeline. CI, 'Continuous Integration'; is an easy method of changing, testing and sharing code (use of code repository and Hugo). CD, 'Continuous Delivery'; refers to the automation of building an application, as well as it's deployment into the production environment (said vudu magic that spots the code change and triggers a build, before GKE creates fresh pods with the new container release inside).</p>\n<p><img src=\"/img/post-0/dockerAutomated.png\" alt=\"Docker Automated Builds\" title=\"Overview of Docker automated builds functionality on Docker Hub web UI\"></p>\n<p>To achieve this, the obvious first choice for enabling easy integration was <a href=\"https://www.howtogeek.com/180167/htg-explains-what-is-github-and-what-do-geeks-use-it-for/\">Github</a>. It's free, and I was also comfortable using it. That way I could have a saved snapchat of each update to my site, with easy access to it from just about every electronic device I could think to work on. The CD side is where things got interesting for me, as I needed to figure out how I could easily trigger a docker build from a git commit, saving myself a step. Docker came to the rescue here, with the <a href=\"https://docs.docker.com/docker-hub/builds/\">'automated build'</a> feature within docker hub. Using a webhook, a push to my github repository initiates a new build on a Docker hosted VM, and then places it in a docker hub repository that you can easily reference within your Kubernetes deployment. As for triggering new pods to be created within GKE? This will hopefully come in the near future 🤞. I have been looking at an awesome tool called <a href=\"https://github.com/fluxcd/flux\">Flux</a>, that provides this kind of functionality. This is something I will hopefully look into soon, but I realised that maybe creating a 'dev' branch to commit to before merging it into the master release would be preferable. This way I won't accidentally publish half my article midsession 😂.</p>\n<p>{{&#x3C; figure src=\"/img/post-0/flux.png\">}}</p>\n<h3>Back to GKE: Deployments, Ingress and... TLS (Torturously Long Setback 😭)</h3>\n<p>Before I crack away with an overview of how I went about working on this part of the project; just a short disclaimer. Due to the number of headaches, misconceptions and design changes that led to this most current configuration, I will keep things brief; <strong>no braincell's shall be damaged in the making of this post.</strong></p>\n<h4>Deployment</h4>\n<p>From the point of view of deployment, this was a pretty simple step after the months of reading I had done about k8s and kubectl. A deployment YAML config file was created to ensure that if needed, I could redeploy the same configuration elsewhere, and minimal configuration would be required. In fact, I actually deleted and recreated my GKE cluster a couple of times during setup (unfortunately I noobed out a few times), and this saved my bacon. I have added my deployment below, and I have added features to it such as <a href=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/\">rolling updates</a> and <a href=\"https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-terminating-with-grace\">grace periods</a> (super super neat!). After having my pods running safely on GKE I thought 'great, this is easy!'. Fortunately... the next stage blew my mind a little.</p>\n<p><img src=\"/img/post-0/yamls.png\" alt=\"Docker Automated Builds\" title=\"Yaml files used for deployment and Ingress\"></p>\n<h4>DNS</h4>\n<p>Google Cloud DNS provided a reliable method of redirecting the user entering the domain name of the site to the appropriate Ingress IP. Ahh wonderful, Ingress. If you've been keeping an eye on the blog, the first post was all about Ingress, so I should be a master at this step. \"It's gonna be a piece of cake\", I thought. No. No it wasn't.</p>\n<h4>Ingress</h4>\n<p><em>Brief Note: While I am sure that all of those reading this will have heard of HTTP/HTTPS, you may be unsure as to what the actual difference is between them. If so read <a href=\"https://www.geeksforgeeks.org/difference-between-http-and-https/\">this 😊</a></em></p>\n<p>From the perspective of configuring ingress from the domain to the desired endpoint using http (non-encrypted), all went as expected. I followed the <a href=\"https://cloud.google.com/kubernetes-engine/docs/tutorials/http-balancer\">documentation</a> provided by Google, and it all went according to plan. The same cannot be said while configuring SSL/TLS. Google cloud provides the capability to automatically have your certificates managed by google... fantastic! Although, as much as I want to tell you that this whole process went smoothly... it really didn't. Granted, this may be due to my lack of maturity as a Kubernetes admin, but the problem boiled down to the fact that no matter how hard I tried.. I just couldn't seem to get requests to default or redirect to port 443 (HTTPS). I tried endless tricks, workarounds, guides, forum post answers... but none brought me to the desired result of secure access 😑.</p>\n<p>{{&#x3C; figure src=\"/img/post-0/LostInWoods2.gif\">}}</p>\n<p>The problem seemed a little to do with limitations in the GKE ingress controller, and maybe I was looking in the wrong place, but documentation was both vague and lacking. Furthermore, let's just say I was not the only one that had issues in this area. So I figured, scrap it. Let's deploy an ingress controller that is fully managed inside of my Kubernetes cluster. 'Aha!' I thought, 'let's use Contour!'. After all I just spent time overviewing it (quick promo for previous <a href=\"https://blog.chaosinthe.dev/posts/first-posts/\">post</a>), so it would be fitting that it was to actually be used for the ingress of this site!</p>\n<p>Following Dave Cheney's <a href=\"https://projectcontour.io/guides/cert-manager/\">guide</a>, that provides a step by step walkthrough for deploying Contour; I was up and running within an hour. Compared to the two days of stumbling around aimlessly (reference to Jim Carey above), this efficiency was welcoming. Also included within the guide (and what I was most excited about) is the steps for deploying cert-manager; a k8s addon for automating the management and issuance of TLS certificates... 'ooh la la' I thought. And 'Ooh la la' I uttered not long later. After deploying Contour and cert-manager, declaring their use through the ingress annotations and pairing the relevant secrets (containing my certificates) was all it took for fully working Ingress with added TLS that was fully enforced by the ingress controller 🍾.</p>\n<h2>Step 3. Step back and Relax</h2>\n<p>So that's it. That is how I went about configuring and deploying the webpage that sits before your very eyes. While this article provides an overview, there were many more headaches, problems, breakdowns and confusions that took place in the process. But overall, I am happy with how it has all turned out. The plan in the coming weeks and months is to flesh it out further, with more articles (of course weekly, I've promised myself), and some added functionality (shiny web UI features 😲).</p>\n<p>If you have felt anything at all about this article, please provide me with some feedback, and I can take it in my stride moving forward with the project. If you have learned something I would also love to hear as that is what this blog is all about! Finally, if you have any ideas about platforms or tools that I could overview, do not hesitate to forward me a suggestion, and I will do my best to provide something informative yet exciting.</p>"
    },
    "_id": "blog/post-0.md",
    "_raw": {
      "sourceFilePath": "blog/post-0.md",
      "sourceFileName": "post-0.md",
      "sourceFileDir": "blog",
      "contentType": "markdown",
      "flattenedPath": "blog/post-0"
    },
    "type": "Doc"
  }
]